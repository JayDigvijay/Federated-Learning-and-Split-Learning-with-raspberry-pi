{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Hybrid 1D-CNN Server Side\n",
    "This code is the server part of ECG Hybrid 1D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 400\n",
    "local_epoch = 1\n",
    "users = 2 # number of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:0\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train and test dataset batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_models = [0] * users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG server model\n",
    "Server side has **1 convolutional layer** and **2 fully connected layers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgServer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgServer, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "#         self.relu1 = nn.LeakyReLU()\n",
    "#         self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "#         self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "#         self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear5 = nn.Linear(32 * 16, 128)\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.linear6 = nn.Linear(128, 5)\n",
    "        self.softmax6 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.linear6(x)\n",
    "        x = self.softmax6(x)\n",
    "        return x   \n",
    "    \n",
    "class Ecgnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgnet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        self.linear5 = nn.Linear(32 * 16, 128)\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.linear6 = nn.Linear(128, 5)\n",
    "        self.softmax6 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.linear6(x)\n",
    "        x = self.softmax6(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(users):\n",
    "    server_models[i] = EcgServer().to(device)\n",
    "ecg_net = Ecgnet().to(device)\n",
    "ecg_server = EcgServer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN server')\n",
    "# summary(ecg_server, (16, 65))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ecgclient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ecgclient, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecgclient(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ecg_client = Ecgclient().to(device)\n",
    "print(ecg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# print('ECG 1D CNN client')\n",
    "# summary(ecg_client, (1, 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the client side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer_server_list = []\n",
    "for i in range(users):\n",
    "    optimizer_server_list.append(Adam(server_models[i].parameters(), lr=lr))\n",
    "\n",
    "datasetsize = [0]*users\n",
    "clientsoclist = [0] * users\n",
    "\n",
    "client_weights = [0] * users\n",
    "server_weights = [0] * users\n",
    "\n",
    "weight_count = 0\n",
    "global_c_weights = copy.deepcopy(ecg_client.state_dict())\n",
    "global_s_weights = copy.deepcopy(server_models[0].state_dict())\n",
    "\n",
    "# for _ in range(users):\n",
    "#     client_weights.append(c_weights)\n",
    "#     server_weights.append(s_weights)\n",
    "\n",
    "start_time = 0\n",
    "lock = Lock()\n",
    "    \n",
    "###########################################################################\n",
    "\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(users)]\n",
    "client_receivesize_list = [[] for i in range(users)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(w, datasize):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, data in enumerate(datasize):\n",
    "        for key in w[i].keys():\n",
    "            w[i][key] *= float(data)\n",
    "    \n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    \n",
    "    \n",
    "\n",
    "# when client use only one kinds of device\n",
    "\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
    "\n",
    "# when client use various devices (cpu, gpu) you need to use it instead\n",
    "#\n",
    "#     for key, val in w_avg.items():\n",
    "#         common_device = val.device\n",
    "#         break\n",
    "#     for key in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             if common_device == 'cpu':\n",
    "#                 w_avg[key] += w[i][key].cpu()\n",
    "#             else:\n",
    "#                 w_avg[key] += w[i][key].cuda()\n",
    "#         w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
    "\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(func, num_user):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    thrs = []\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with', addr)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    print(\"timmer start!\")\n",
    "    start_time = time.time()    # store start time\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(userid, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    global datasetsize\n",
    "\n",
    "    msg = {\n",
    "        'rounds': rounds,\n",
    "        'local_epoch': local_epoch,\n",
    "        'client_id': userid\n",
    "    }\n",
    "\n",
    "    datasize = send_msg(conn, msg)    #send epoch\n",
    "    total_sendsize_list.append(datasize)\n",
    "    client_sendsize_list[userid].append(datasize)\n",
    "\n",
    "    \n",
    "    msg, datasize = recv_msg(conn)            # get total_batch of train dataset\n",
    "    total_batch = msg['total_batch']\n",
    "    train_dataset_size = msg['train_dataset_size']\n",
    "    total_receivesize_list.append(datasize)\n",
    "    client_receivesize_list[userid].append(datasize)\n",
    "    with lock:\n",
    "        datasetsize[userid] = train_dataset_size\n",
    "        weight_count += 1\n",
    "    \n",
    "    train(userid, total_batch, num_users, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(userid, total_batch, num_users, client_conn):\n",
    "    global client_weights\n",
    "    global weight_count\n",
    "    global global_c_weights\n",
    "    global global_s_weights\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        \n",
    "        with lock:\n",
    "            if weight_count == num_users:\n",
    "                for i, conn in enumerate(clientsoclist):\n",
    "                    datasize = send_msg(conn, global_c_weights)\n",
    "                    total_sendsize_list.append(datasize)\n",
    "                    client_sendsize_list[i].append(datasize)\n",
    "                    train_sendsize_list.append(datasize)\n",
    "                    weight_count = 0\n",
    "                    server_models[i].load_state_dict(global_s_weights)\n",
    "                    server_models[i].eval()\n",
    "                \n",
    "        for l in range(local_epoch):\n",
    "            \n",
    "                        \n",
    "            for i in range(total_batch):\n",
    "                optimizer_server_list[userid].zero_grad()  # initialize all gradients to zero\n",
    "\n",
    "                msg, datasize = recv_msg(client_conn)  # receive client message from socket\n",
    "                total_receivesize_list.append(datasize)\n",
    "                client_receivesize_list[userid].append(datasize)\n",
    "                train_receivesize_list.append(datasize)\n",
    "\n",
    "                client_output_cpu = msg['client_output']  # client output tensor\n",
    "                label = msg['label']  # label\n",
    "\n",
    "                client_output = client_output_cpu.to(device)\n",
    "                label = label.clone().detach().long().to(device)\n",
    "\n",
    "                output = server_models[userid](client_output)  # forward propagation\n",
    "                loss = criterion(output, label)  # calculates cross-entropy loss\n",
    "                loss.backward()  # backward propagation\n",
    "                msg = client_output_cpu.grad.clone().detach()\n",
    "\n",
    "                datasize = send_msg(client_conn, msg)\n",
    "                total_sendsize_list.append(datasize)\n",
    "                client_sendsize_list[userid].append(datasize)\n",
    "                train_sendsize_list.append(datasize)\n",
    "\n",
    "                optimizer_server_list[userid].step()\n",
    "                \n",
    "            \n",
    "        c_weights, datasize = recv_msg(client_conn)\n",
    "        total_receivesize_list.append(datasize)\n",
    "        client_receivesize_list[userid].append(datasize)\n",
    "        train_receivesize_list.append(datasize)\n",
    "        with lock:\n",
    "            client_weights[userid] = c_weights\n",
    "            server_weights[userid] = copy.deepcopy(server_models[userid].state_dict())\n",
    "            weight_count += 1\n",
    "            if weight_count == num_users:\n",
    "                #average\n",
    "                global_c_weights = average_weights(client_weights, datasetsize)\n",
    "                global_s_weights = average_weights(server_weights, datasetsize)\n",
    "                \n",
    "                # acc\n",
    "                \n",
    "\n",
    "#                 ecg_client.load_state_dict(global_c_weights)\n",
    "#                 ecg_client.to(device)\n",
    "\n",
    "#                 ecg_server.load_state_dict(global_s_weights)\n",
    "#                 ecg_server.to(device)\n",
    "                \n",
    "#                 # train acc\n",
    "#                 with torch.no_grad():\n",
    "#                     corr_num = 0\n",
    "#                     total_num = 0\n",
    "#                     train_loss = 0.0\n",
    "#                     for j, trn in enumerate(train_loader):\n",
    "#                         trn_x, trn_label = trn\n",
    "#                         trn_x = trn_x.to(device)\n",
    "\n",
    "#                         trn_label = trn_label.clone().detach().long().to(device)\n",
    "\n",
    "\n",
    "#                         #trn_output = ecg_net(trn_x)\n",
    "#                         trn_output = ecg_client(trn_x)\n",
    "#                         trn_output = ecg_server(trn_output)\n",
    "\n",
    "#                         loss = criterion(trn_output, trn_label)\n",
    "\n",
    "#                         train_loss += loss.item()\n",
    "#                         model_label = trn_output.argmax(dim=1)\n",
    "#                         corr = trn_label[trn_label == model_label].size(0)\n",
    "#                         corr_num += corr\n",
    "#                         total_num += trn_label.size(0)\n",
    "#                     train_accuracy = corr_num / total_num * 100\n",
    "#                     r_train_loss = train_loss / len(train_loader)\n",
    "#                     print(\"Round{}'s train_acc: {:.2f}%, train_loss: {:.4f}\".format(r, train_accuracy, r_train_loss))\n",
    "#                     train_acc.append(train_accuracy)\n",
    "#                 # test acc\n",
    "#                 with torch.no_grad():\n",
    "#                     corr_num = 0\n",
    "#                     total_num = 0\n",
    "#                     val_loss = 0.0\n",
    "#                     for j, val in enumerate(test_loader):\n",
    "#                         val_x, val_label = val\n",
    "#                         val_x = val_x.to(device)\n",
    "#                         val_label = val_label.to(device)\n",
    "\n",
    "#                         #val_output = ecg_net(val_x)\n",
    "#                         val_output = ecg_client(val_x)\n",
    "#                         val_output = ecg_server(val_output)\n",
    "\n",
    "#                         val_label = val_label.long()\n",
    "#                         loss = criterion(val_output, val_label)\n",
    "#                         val_loss += loss.item()\n",
    "#                         model_label = val_output.argmax(dim=1)\n",
    "#                         corr = val_label[val_label == model_label].size(0)\n",
    "#                         corr_num += corr\n",
    "#                         total_num += val_label.size(0)\n",
    "#                     test_accuracy = corr_num / total_num * 100\n",
    "#                     test_loss = val_loss / len(test_loader)\n",
    "#                     print(\"Round{}'s test_acc: {:.2f}%, test_loss: {:.4f}\".format(r, test_accuracy, test_loss))\n",
    "#                     test_acc.append(test_accuracy)\n",
    "                \n",
    "        print(\"round {}'s user {} is done\".format(r, userid))      \n",
    "            \n",
    "    print('{} is complite'.format(userid))\n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.83.1\n"
     ]
    }
   ],
   "source": [
    "host = socket.gethostbyname(socket.gethostname())\n",
    "port = 10080\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to connect\n"
     ]
    }
   ],
   "source": [
    "s = socket.socket()\n",
    "try:\n",
    "    s.bind((host, port))\n",
    "    print('Success to connect')\n",
    "except:\n",
    "    print('Fail to connect')\n",
    "    \n",
    "s.listen(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conntected with ('192.168.83.1', 5148)\n",
      "Conntected with ('192.168.83.1', 5149)\n",
      "timmer start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0's user 1 is done\n",
      "Round0's train_acc: 61.93%, train_loss: 1.2947\n",
      "Round0's test_acc: 62.97%, test_loss: 1.2893\n",
      "round 0's user 0 is done\n",
      "round 1's user 1 is done\n",
      "Round1's train_acc: 78.55%, train_loss: 1.1207\n",
      "Round1's test_acc: 79.63%, test_loss: 1.1125\n",
      "round 1's user 0 is done\n",
      "round 2's user 1 is done\n",
      "Round2's train_acc: 85.65%, train_loss: 1.0488\n",
      "Round2's test_acc: 86.51%, test_loss: 1.0410\n",
      "round 2's user 0 is done\n",
      "round 3's user 1 is done\n",
      "Round3's train_acc: 86.27%, train_loss: 1.0430\n",
      "Round3's test_acc: 86.89%, test_loss: 1.0375\n",
      "round 3's user 0 is done\n",
      "round 4's user 1 is done\n",
      "Round4's train_acc: 85.21%, train_loss: 1.0543\n",
      "Round4's test_acc: 86.01%, test_loss: 1.0476\n",
      "round 4's user 0 is done\n",
      "round 5's user 0 is done\n",
      "Round5's train_acc: 87.13%, train_loss: 1.0325\n",
      "Round5's test_acc: 88.03%, test_loss: 1.0252\n",
      "round 5's user 1 is done\n",
      "round 6's user 1 is done\n",
      "Round6's train_acc: 87.38%, train_loss: 1.0313\n",
      "Round6's test_acc: 87.73%, test_loss: 1.0267\n",
      "round 6's user 0 is done\n",
      "round 7's user 1 is done\n",
      "Round7's train_acc: 87.87%, train_loss: 1.0268\n",
      "Round7's test_acc: 88.39%, test_loss: 1.0213\n",
      "round 7's user 0 is done\n",
      "round 8's user 1 is done\n",
      "Round8's train_acc: 87.69%, train_loss: 1.0277\n",
      "Round8's test_acc: 88.28%, test_loss: 1.0214\n",
      "round 8's user 0 is done\n",
      "round 9's user 1 is done\n",
      "Round9's train_acc: 88.15%, train_loss: 1.0226\n",
      "Round9's test_acc: 88.82%, test_loss: 1.0161\n",
      "round 9's user 0 is done\n",
      "round 10's user 1 is done\n",
      "Round10's train_acc: 87.47%, train_loss: 1.0298\n",
      "Round10's test_acc: 88.31%, test_loss: 1.0217\n",
      "round 10's user 0 is done\n",
      "round 11's user 1 is done\n",
      "Round11's train_acc: 87.89%, train_loss: 1.0257\n",
      "Round11's test_acc: 88.58%, test_loss: 1.0195\n",
      "round 11's user 0 is done\n",
      "round 12's user 1 is done\n",
      "Round12's train_acc: 88.04%, train_loss: 1.0231\n",
      "Round12's test_acc: 88.59%, test_loss: 1.0179\n",
      "round 12's user 0 is done\n",
      "round 13's user 1 is done\n",
      "Round13's train_acc: 88.29%, train_loss: 1.0208\n",
      "Round13's test_acc: 88.80%, test_loss: 1.0160\n",
      "round 13's user 0 is done\n",
      "round 14's user 1 is done\n",
      "Round14's train_acc: 88.33%, train_loss: 1.0212\n",
      "Round14's test_acc: 88.83%, test_loss: 1.0161\n",
      "round 14's user 0 is done\n",
      "round 15's user 1 is done\n",
      "Round15's train_acc: 88.46%, train_loss: 1.0196\n",
      "Round15's test_acc: 89.00%, test_loss: 1.0142\n",
      "round 15's user 0 is done\n",
      "round 16's user 1 is done\n",
      "Round16's train_acc: 88.46%, train_loss: 1.0195\n",
      "Round16's test_acc: 89.00%, test_loss: 1.0142\n",
      "round 16's user 0 is done\n",
      "round 17's user 0 is done\n",
      "Round17's train_acc: 88.47%, train_loss: 1.0192\n",
      "Round17's test_acc: 89.05%, test_loss: 1.0139\n",
      "round 17's user 1 is done\n",
      "round 18's user 1 is done\n",
      "Round18's train_acc: 88.43%, train_loss: 1.0189\n",
      "Round18's test_acc: 89.04%, test_loss: 1.0135\n",
      "round 18's user 0 is done\n",
      "round 19's user 1 is done\n",
      "Round19's train_acc: 88.42%, train_loss: 1.0201\n",
      "Round19's test_acc: 88.98%, test_loss: 1.0144\n",
      "round 19's user 0 is done\n",
      "round 20's user 1 is done\n",
      "Round20's train_acc: 88.64%, train_loss: 1.0175\n",
      "Round20's test_acc: 89.25%, test_loss: 1.0117\n",
      "round 20's user 0 is done\n",
      "round 21's user 0 is done\n",
      "Round21's train_acc: 88.84%, train_loss: 1.0155\n",
      "Round21's test_acc: 89.23%, test_loss: 1.0118\n",
      "round 21's user 1 is done\n",
      "round 22's user 0 is done\n",
      "Round22's train_acc: 88.87%, train_loss: 1.0161\n",
      "Round22's test_acc: 89.29%, test_loss: 1.0115\n",
      "round 22's user 1 is done\n",
      "round 23's user 1 is done\n",
      "Round23's train_acc: 88.80%, train_loss: 1.0160\n",
      "Round23's test_acc: 89.26%, test_loss: 1.0115\n",
      "round 23's user 0 is done\n",
      "round 24's user 0 is done\n",
      "Round24's train_acc: 88.93%, train_loss: 1.0140\n",
      "Round24's test_acc: 89.39%, test_loss: 1.0101\n",
      "round 24's user 1 is done\n",
      "round 25's user 1 is done\n",
      "Round25's train_acc: 88.91%, train_loss: 1.0153\n",
      "Round25's test_acc: 89.31%, test_loss: 1.0113\n",
      "round 25's user 0 is done\n",
      "round 26's user 1 is done\n",
      "Round26's train_acc: 88.80%, train_loss: 1.0164\n",
      "Round26's test_acc: 89.12%, test_loss: 1.0132\n",
      "round 26's user 0 is done\n",
      "round 27's user 0 is done\n",
      "Round27's train_acc: 89.15%, train_loss: 1.0127\n",
      "Round27's test_acc: 89.60%, test_loss: 1.0083\n",
      "round 27's user 1 is done\n",
      "round 28's user 1 is done\n",
      "Round28's train_acc: 88.95%, train_loss: 1.0145\n",
      "Round28's test_acc: 89.38%, test_loss: 1.0107\n",
      "round 28's user 0 is done\n",
      "round 29's user 1 is done\n",
      "Round29's train_acc: 89.11%, train_loss: 1.0126\n",
      "Round29's test_acc: 89.60%, test_loss: 1.0084\n",
      "round 29's user 0 is done\n",
      "round 30's user 1 is done\n",
      "Round30's train_acc: 88.96%, train_loss: 1.0144\n",
      "Round30's test_acc: 89.30%, test_loss: 1.0108\n",
      "round 30's user 0 is done\n",
      "round 31's user 1 is done\n",
      "Round31's train_acc: 89.08%, train_loss: 1.0128\n",
      "Round31's test_acc: 89.45%, test_loss: 1.0090\n",
      "round 31's user 0 is done\n",
      "round 32's user 0 is done\n",
      "Round32's train_acc: 89.03%, train_loss: 1.0141\n",
      "Round32's test_acc: 89.55%, test_loss: 1.0092\n",
      "round 32's user 1 is done\n",
      "round 33's user 1 is done\n",
      "Round33's train_acc: 89.10%, train_loss: 1.0131\n",
      "Round33's test_acc: 89.39%, test_loss: 1.0100\n",
      "round 33's user 0 is done\n",
      "round 34's user 1 is done\n",
      "Round34's train_acc: 89.33%, train_loss: 1.0105\n",
      "Round34's test_acc: 89.78%, test_loss: 1.0064\n",
      "round 34's user 0 is done\n",
      "round 35's user 1 is done\n",
      "Round35's train_acc: 89.20%, train_loss: 1.0118\n",
      "Round35's test_acc: 89.72%, test_loss: 1.0068\n",
      "round 35's user 0 is done\n",
      "round 36's user 1 is done\n",
      "Round36's train_acc: 89.08%, train_loss: 1.0128\n",
      "Round36's test_acc: 89.52%, test_loss: 1.0086\n",
      "round 36's user 0 is done\n",
      "round 37's user 1 is done\n",
      "Round37's train_acc: 89.33%, train_loss: 1.0109\n",
      "Round37's test_acc: 89.72%, test_loss: 1.0067\n",
      "round 37's user 0 is done\n",
      "round 38's user 0 is done\n",
      "Round38's train_acc: 89.28%, train_loss: 1.0109\n",
      "Round38's test_acc: 89.60%, test_loss: 1.0077\n",
      "round 38's user 1 is done\n",
      "round 39's user 1 is done\n",
      "Round39's train_acc: 89.27%, train_loss: 1.0106\n",
      "Round39's test_acc: 89.66%, test_loss: 1.0067\n",
      "round 39's user 0 is done\n",
      "round 40's user 0 is done\n",
      "Round40's train_acc: 89.29%, train_loss: 1.0108\n",
      "Round40's test_acc: 89.76%, test_loss: 1.0062\n",
      "round 40's user 1 is done\n",
      "round 41's user 1 is done\n",
      "Round41's train_acc: 89.35%, train_loss: 1.0105\n",
      "Round41's test_acc: 89.69%, test_loss: 1.0070\n",
      "round 41's user 0 is done\n",
      "round 42's user 0 is done\n",
      "Round42's train_acc: 89.44%, train_loss: 1.0090\n",
      "Round42's test_acc: 89.87%, test_loss: 1.0050\n",
      "round 42's user 1 is done\n",
      "round 43's user 1 is done\n",
      "Round43's train_acc: 89.32%, train_loss: 1.0106\n",
      "Round43's test_acc: 89.60%, test_loss: 1.0074\n",
      "round 43's user 0 is done\n",
      "round 44's user 1 is done\n",
      "Round44's train_acc: 89.17%, train_loss: 1.0111\n",
      "Round44's test_acc: 89.75%, test_loss: 1.0058\n",
      "round 44's user 0 is done\n",
      "round 45's user 0 is done\n",
      "Round45's train_acc: 89.47%, train_loss: 1.0087\n",
      "Round45's test_acc: 89.94%, test_loss: 1.0040\n",
      "round 45's user 1 is done\n",
      "round 46's user 1 is done\n",
      "Round46's train_acc: 89.78%, train_loss: 1.0061\n",
      "Round46's test_acc: 90.01%, test_loss: 1.0032\n",
      "round 46's user 0 is done\n",
      "round 47's user 1 is done\n",
      "Round47's train_acc: 89.63%, train_loss: 1.0069\n",
      "Round47's test_acc: 89.94%, test_loss: 1.0037\n",
      "round 47's user 0 is done\n",
      "round 48's user 0 is done\n",
      "Round48's train_acc: 89.70%, train_loss: 1.0058\n",
      "Round48's test_acc: 90.06%, test_loss: 1.0024\n",
      "round 48's user 1 is done\n",
      "round 49's user 0 is done\n",
      "Round49's train_acc: 89.76%, train_loss: 1.0054\n",
      "Round49's test_acc: 90.08%, test_loss: 1.0027\n",
      "round 49's user 1 is done\n",
      "round 50's user 1 is done\n",
      "Round50's train_acc: 89.79%, train_loss: 1.0052\n",
      "Round50's test_acc: 90.02%, test_loss: 1.0029\n",
      "round 50's user 0 is done\n",
      "round 51's user 0 is done\n",
      "Round51's train_acc: 89.41%, train_loss: 1.0086\n",
      "Round51's test_acc: 89.76%, test_loss: 1.0052\n",
      "round 51's user 1 is done\n",
      "round 52's user 0 is done\n",
      "Round52's train_acc: 89.57%, train_loss: 1.0075\n",
      "Round52's test_acc: 89.88%, test_loss: 1.0045\n",
      "round 52's user 1 is done\n",
      "round 53's user 1 is done\n",
      "Round53's train_acc: 89.98%, train_loss: 1.0032\n",
      "Round53's test_acc: 90.27%, test_loss: 1.0004\n",
      "round 53's user 0 is done\n",
      "round 54's user 1 is done\n",
      "Round54's train_acc: 89.87%, train_loss: 1.0043\n",
      "Round54's test_acc: 90.18%, test_loss: 1.0013\n",
      "round 54's user 0 is done\n",
      "round 55's user 1 is done\n",
      "Round55's train_acc: 90.02%, train_loss: 1.0033\n",
      "Round55's test_acc: 90.40%, test_loss: 0.9997\n",
      "round 55's user 0 is done\n",
      "round 56's user 0 is done\n",
      "Round56's train_acc: 89.89%, train_loss: 1.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round56's test_acc: 90.18%, test_loss: 1.0013\n",
      "round 56's user 1 is done\n",
      "round 57's user 1 is done\n",
      "Round57's train_acc: 89.97%, train_loss: 1.0042\n",
      "Round57's test_acc: 90.25%, test_loss: 1.0010\n",
      "round 57's user 0 is done\n",
      "round 58's user 1 is done\n",
      "Round58's train_acc: 89.88%, train_loss: 1.0041\n",
      "Round58's test_acc: 90.18%, test_loss: 1.0010\n",
      "round 58's user 0 is done\n",
      "round 59's user 0 is done\n",
      "Round59's train_acc: 90.06%, train_loss: 1.0018\n",
      "Round59's test_acc: 90.37%, test_loss: 0.9992\n",
      "round 59's user 1 is done\n",
      "round 60's user 1 is done\n",
      "Round60's train_acc: 89.94%, train_loss: 1.0039\n",
      "Round60's test_acc: 90.25%, test_loss: 1.0007\n",
      "round 60's user 0 is done\n",
      "round 61's user 1 is done\n",
      "Round61's train_acc: 90.18%, train_loss: 1.0006\n",
      "Round61's test_acc: 90.39%, test_loss: 0.9984\n",
      "round 61's user 0 is done\n",
      "round 62's user 1 is done\n",
      "Round62's train_acc: 89.92%, train_loss: 1.0044\n",
      "Round62's test_acc: 90.20%, test_loss: 1.0014\n",
      "round 62's user 0 is done\n",
      "round 63's user 1 is done\n",
      "Round63's train_acc: 90.04%, train_loss: 1.0026\n",
      "Round63's test_acc: 90.12%, test_loss: 1.0017\n",
      "round 63's user 0 is done\n",
      "round 64's user 0 is done\n",
      "Round64's train_acc: 90.07%, train_loss: 1.0027\n",
      "Round64's test_acc: 90.33%, test_loss: 1.0002\n",
      "round 64's user 1 is done\n",
      "round 65's user 1 is done\n",
      "Round65's train_acc: 89.60%, train_loss: 1.0077\n",
      "Round65's test_acc: 90.04%, test_loss: 1.0032\n",
      "round 65's user 0 is done\n",
      "round 66's user 0 is done\n",
      "Round66's train_acc: 90.18%, train_loss: 1.0005\n",
      "Round66's test_acc: 90.37%, test_loss: 0.9986\n",
      "round 66's user 1 is done\n",
      "round 67's user 1 is done\n",
      "Round67's train_acc: 90.25%, train_loss: 0.9999\n",
      "Round67's test_acc: 90.43%, test_loss: 0.9980\n",
      "round 67's user 0 is done\n",
      "round 68's user 0 is done\n",
      "Round68's train_acc: 90.27%, train_loss: 0.9996\n",
      "Round68's test_acc: 90.49%, test_loss: 0.9973\n",
      "round 68's user 1 is done\n",
      "round 69's user 0 is done\n",
      "Round69's train_acc: 90.12%, train_loss: 1.0013\n",
      "Round69's test_acc: 90.33%, test_loss: 0.9990\n",
      "round 69's user 1 is done\n",
      "round 70's user 1 is done\n",
      "Round70's train_acc: 90.21%, train_loss: 1.0002\n",
      "Round70's test_acc: 90.33%, test_loss: 0.9987\n",
      "round 70's user 0 is done\n",
      "round 71's user 1 is done\n",
      "Round71's train_acc: 90.13%, train_loss: 1.0011\n",
      "Round71's test_acc: 90.34%, test_loss: 0.9991\n",
      "round 71's user 0 is done\n",
      "round 72's user 0 is done\n",
      "Round72's train_acc: 90.28%, train_loss: 0.9993\n",
      "Round72's test_acc: 90.46%, test_loss: 0.9974\n",
      "round 72's user 1 is done\n",
      "round 73's user 1 is done\n",
      "Round73's train_acc: 90.31%, train_loss: 0.9993\n",
      "Round73's test_acc: 90.43%, test_loss: 0.9976\n",
      "round 73's user 0 is done\n",
      "round 74's user 1 is done\n",
      "Round74's train_acc: 90.27%, train_loss: 0.9991\n",
      "Round74's test_acc: 90.51%, test_loss: 0.9971\n",
      "round 74's user 0 is done\n",
      "round 75's user 1 is done\n",
      "Round75's train_acc: 90.35%, train_loss: 0.9986\n",
      "Round75's test_acc: 90.55%, test_loss: 0.9970\n",
      "round 75's user 0 is done\n",
      "round 76's user 0 is done\n",
      "Round76's train_acc: 90.28%, train_loss: 1.0002\n",
      "Round76's test_acc: 90.54%, test_loss: 0.9977\n",
      "round 76's user 1 is done\n",
      "round 77's user 1 is done\n",
      "Round77's train_acc: 89.85%, train_loss: 1.0050\n",
      "Round77's test_acc: 90.21%, test_loss: 1.0018\n",
      "round 77's user 0 is done\n",
      "round 78's user 1 is done\n",
      "Round78's train_acc: 90.37%, train_loss: 0.9982\n",
      "Round78's test_acc: 90.59%, test_loss: 0.9962\n",
      "round 78's user 0 is done\n",
      "round 79's user 1 is done\n",
      "Round79's train_acc: 90.12%, train_loss: 1.0008\n",
      "Round79's test_acc: 90.34%, test_loss: 0.9986\n",
      "round 79's user 0 is done\n",
      "round 80's user 1 is done\n",
      "Round80's train_acc: 90.33%, train_loss: 0.9987\n",
      "Round80's test_acc: 90.43%, test_loss: 0.9974\n",
      "round 80's user 0 is done\n",
      "round 81's user 1 is done\n",
      "Round81's train_acc: 90.05%, train_loss: 1.0016\n",
      "Round81's test_acc: 90.34%, test_loss: 0.9986\n",
      "round 81's user 0 is done\n",
      "round 82's user 1 is done\n",
      "Round82's train_acc: 90.02%, train_loss: 1.0022\n",
      "Round82's test_acc: 90.33%, test_loss: 0.9994\n",
      "round 82's user 0 is done\n",
      "round 83's user 0 is done\n",
      "Round83's train_acc: 90.33%, train_loss: 0.9988\n",
      "Round83's test_acc: 90.53%, test_loss: 0.9966\n",
      "round 83's user 1 is done\n",
      "round 84's user 1 is done\n",
      "Round84's train_acc: 90.28%, train_loss: 0.9994\n",
      "Round84's test_acc: 90.53%, test_loss: 0.9967\n",
      "round 84's user 0 is done\n",
      "round 85's user 1 is done\n",
      "Round85's train_acc: 90.31%, train_loss: 0.9983\n",
      "Round85's test_acc: 90.52%, test_loss: 0.9966\n",
      "round 85's user 0 is done\n",
      "round 86's user 1 is done\n",
      "Round86's train_acc: 90.29%, train_loss: 0.9990\n",
      "Round86's test_acc: 90.58%, test_loss: 0.9964\n",
      "round 86's user 0 is done\n",
      "round 87's user 1 is done\n",
      "Round87's train_acc: 90.37%, train_loss: 0.9984\n",
      "Round87's test_acc: 90.55%, test_loss: 0.9966\n",
      "round 87's user 0 is done\n",
      "round 88's user 1 is done\n",
      "Round88's train_acc: 90.40%, train_loss: 0.9977\n",
      "Round88's test_acc: 90.67%, test_loss: 0.9952\n",
      "round 88's user 0 is done\n",
      "round 89's user 1 is done\n",
      "Round89's train_acc: 90.41%, train_loss: 0.9976\n",
      "Round89's test_acc: 90.61%, test_loss: 0.9958\n",
      "round 89's user 0 is done\n",
      "round 90's user 1 is done\n",
      "Round90's train_acc: 90.40%, train_loss: 0.9978\n",
      "Round90's test_acc: 90.59%, test_loss: 0.9959\n",
      "round 90's user 0 is done\n",
      "round 91's user 0 is done\n",
      "Round91's train_acc: 90.37%, train_loss: 0.9982\n",
      "Round91's test_acc: 90.58%, test_loss: 0.9962\n",
      "round 91's user 1 is done\n",
      "round 92's user 1 is done\n",
      "Round92's train_acc: 90.44%, train_loss: 0.9972\n",
      "Round92's test_acc: 90.52%, test_loss: 0.9962\n",
      "round 92's user 0 is done\n",
      "round 93's user 0 is done\n",
      "Round93's train_acc: 90.40%, train_loss: 0.9975\n",
      "Round93's test_acc: 90.61%, test_loss: 0.9957\n",
      "round 93's user 1 is done\n",
      "round 94's user 1 is done\n",
      "Round94's train_acc: 90.45%, train_loss: 0.9970\n",
      "Round94's test_acc: 90.62%, test_loss: 0.9954\n",
      "round 94's user 0 is done\n",
      "round 95's user 0 is done\n",
      "Round95's train_acc: 90.39%, train_loss: 0.9972\n",
      "Round95's test_acc: 90.57%, test_loss: 0.9956\n",
      "round 95's user 1 is done\n",
      "round 96's user 1 is done\n",
      "Round96's train_acc: 90.43%, train_loss: 0.9972\n",
      "Round96's test_acc: 90.65%, test_loss: 0.9951\n",
      "round 96's user 0 is done\n",
      "round 97's user 1 is done\n",
      "Round97's train_acc: 90.46%, train_loss: 0.9969\n",
      "Round97's test_acc: 90.63%, test_loss: 0.9953\n",
      "round 97's user 0 is done\n",
      "round 98's user 1 is done\n",
      "Round98's train_acc: 90.38%, train_loss: 0.9978\n",
      "Round98's test_acc: 90.54%, test_loss: 0.9966\n",
      "round 98's user 0 is done\n",
      "round 99's user 1 is done\n",
      "Round99's train_acc: 90.51%, train_loss: 0.9963\n",
      "Round99's test_acc: 90.68%, test_loss: 0.9947\n",
      "round 99's user 0 is done\n",
      "round 100's user 1 is done\n",
      "Round100's train_acc: 90.51%, train_loss: 0.9961\n",
      "Round100's test_acc: 90.69%, test_loss: 0.9944\n",
      "round 100's user 0 is done\n",
      "round 101's user 1 is done\n",
      "Round101's train_acc: 90.42%, train_loss: 0.9977\n",
      "Round101's test_acc: 90.52%, test_loss: 0.9969\n",
      "round 101's user 0 is done\n",
      "round 102's user 1 is done\n",
      "Round102's train_acc: 90.49%, train_loss: 0.9966\n",
      "Round102's test_acc: 90.69%, test_loss: 0.9947\n",
      "round 102's user 0 is done\n",
      "round 103's user 0 is done\n",
      "Round103's train_acc: 90.42%, train_loss: 0.9971\n",
      "Round103's test_acc: 90.60%, test_loss: 0.9954\n",
      "round 103's user 1 is done\n",
      "round 104's user 1 is done\n",
      "Round104's train_acc: 90.43%, train_loss: 0.9974\n",
      "Round104's test_acc: 90.60%, test_loss: 0.9957\n",
      "round 104's user 0 is done\n",
      "round 105's user 1 is done\n",
      "Round105's train_acc: 90.52%, train_loss: 0.9963\n",
      "Round105's test_acc: 90.64%, test_loss: 0.9947\n",
      "round 105's user 0 is done\n",
      "round 106's user 0 is done\n",
      "Round106's train_acc: 90.40%, train_loss: 0.9974\n",
      "Round106's test_acc: 90.67%, test_loss: 0.9952\n",
      "round 106's user 1 is done\n",
      "round 107's user 0 is done\n",
      "Round107's train_acc: 90.52%, train_loss: 0.9961\n",
      "Round107's test_acc: 90.71%, test_loss: 0.9943\n",
      "round 107's user 1 is done\n",
      "round 108's user 0 is done\n",
      "Round108's train_acc: 90.49%, train_loss: 0.9965\n",
      "Round108's test_acc: 90.71%, test_loss: 0.9946\n",
      "round 108's user 1 is done\n",
      "round 109's user 0 is done\n",
      "Round109's train_acc: 90.43%, train_loss: 0.9978\n",
      "Round109's test_acc: 90.68%, test_loss: 0.9957\n",
      "round 109's user 1 is done\n",
      "round 110's user 1 is done\n",
      "Round110's train_acc: 90.50%, train_loss: 0.9962\n",
      "Round110's test_acc: 90.67%, test_loss: 0.9946\n",
      "round 110's user 0 is done\n",
      "round 111's user 1 is done\n",
      "Round111's train_acc: 90.46%, train_loss: 0.9969\n",
      "Round111's test_acc: 90.63%, test_loss: 0.9954\n",
      "round 111's user 0 is done\n",
      "round 112's user 0 is done\n",
      "Round112's train_acc: 90.49%, train_loss: 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round112's test_acc: 90.71%, test_loss: 0.9945\n",
      "round 112's user 1 is done\n",
      "round 113's user 0 is done\n",
      "Round113's train_acc: 90.54%, train_loss: 0.9958\n",
      "Round113's test_acc: 90.70%, test_loss: 0.9943\n",
      "round 113's user 1 is done\n",
      "round 114's user 0 is done\n",
      "Round114's train_acc: 90.61%, train_loss: 0.9953\n",
      "Round114's test_acc: 90.77%, test_loss: 0.9939\n",
      "round 114's user 1 is done\n",
      "round 115's user 0 is done\n",
      "Round115's train_acc: 90.60%, train_loss: 0.9953\n",
      "Round115's test_acc: 90.76%, test_loss: 0.9939\n",
      "round 115's user 1 is done\n",
      "round 116's user 0 is done\n",
      "Round116's train_acc: 90.62%, train_loss: 0.9951\n",
      "Round116's test_acc: 90.74%, test_loss: 0.9940\n",
      "round 116's user 1 is done\n",
      "round 117's user 0 is done\n",
      "Round117's train_acc: 90.71%, train_loss: 0.9943\n",
      "Round117's test_acc: 90.88%, test_loss: 0.9928\n",
      "round 117's user 1 is done\n",
      "round 118's user 1 is done\n",
      "Round118's train_acc: 90.59%, train_loss: 0.9951\n",
      "Round118's test_acc: 90.63%, test_loss: 0.9950\n",
      "round 118's user 0 is done\n",
      "round 119's user 1 is done\n",
      "Round119's train_acc: 90.67%, train_loss: 0.9946\n",
      "Round119's test_acc: 90.80%, test_loss: 0.9935\n",
      "round 119's user 0 is done\n",
      "round 120's user 0 is done\n",
      "Round120's train_acc: 90.55%, train_loss: 0.9957\n",
      "Round120's test_acc: 90.60%, test_loss: 0.9952\n",
      "round 120's user 1 is done\n",
      "round 121's user 1 is done\n",
      "Round121's train_acc: 90.68%, train_loss: 0.9944\n",
      "Round121's test_acc: 90.77%, test_loss: 0.9935\n",
      "round 121's user 0 is done\n",
      "round 122's user 1 is done\n",
      "Round122's train_acc: 90.51%, train_loss: 0.9964\n",
      "Round122's test_acc: 90.55%, test_loss: 0.9961\n",
      "round 122's user 0 is done\n",
      "round 123's user 0 is done\n",
      "Round123's train_acc: 90.72%, train_loss: 0.9939\n",
      "Round123's test_acc: 90.75%, test_loss: 0.9937\n",
      "round 123's user 1 is done\n",
      "round 124's user 0 is done\n",
      "Round124's train_acc: 90.56%, train_loss: 0.9958\n",
      "Round124's test_acc: 90.57%, test_loss: 0.9955\n",
      "round 124's user 1 is done\n",
      "round 125's user 1 is done\n",
      "Round125's train_acc: 90.70%, train_loss: 0.9943\n",
      "Round125's test_acc: 90.83%, test_loss: 0.9929\n",
      "round 125's user 0 is done\n",
      "round 126's user 1 is done\n",
      "Round126's train_acc: 90.77%, train_loss: 0.9935\n",
      "Round126's test_acc: 90.83%, test_loss: 0.9929\n",
      "round 126's user 0 is done\n",
      "round 127's user 0 is done\n",
      "Round127's train_acc: 90.78%, train_loss: 0.9936\n",
      "Round127's test_acc: 90.80%, test_loss: 0.9934\n",
      "round 127's user 1 is done\n",
      "round 128's user 1 is done\n",
      "Round128's train_acc: 90.74%, train_loss: 0.9938\n",
      "Round128's test_acc: 90.80%, test_loss: 0.9932\n",
      "round 128's user 0 is done\n",
      "round 129's user 1 is done\n",
      "Round129's train_acc: 90.77%, train_loss: 0.9934\n",
      "Round129's test_acc: 90.89%, test_loss: 0.9925\n",
      "round 129's user 0 is done\n",
      "round 130's user 1 is done\n",
      "Round130's train_acc: 90.49%, train_loss: 0.9966\n",
      "Round130's test_acc: 90.55%, test_loss: 0.9959\n",
      "round 130's user 0 is done\n",
      "round 131's user 1 is done\n",
      "Round131's train_acc: 90.84%, train_loss: 0.9928\n",
      "Round131's test_acc: 90.89%, test_loss: 0.9920\n",
      "round 131's user 0 is done\n",
      "round 132's user 1 is done\n",
      "Round132's train_acc: 90.65%, train_loss: 0.9949\n",
      "Round132's test_acc: 90.80%, test_loss: 0.9937\n",
      "round 132's user 0 is done\n",
      "round 133's user 1 is done\n",
      "Round133's train_acc: 90.89%, train_loss: 0.9924\n",
      "Round133's test_acc: 90.86%, test_loss: 0.9925\n",
      "round 133's user 0 is done\n",
      "round 134's user 1 is done\n",
      "Round134's train_acc: 90.98%, train_loss: 0.9914\n",
      "Round134's test_acc: 90.97%, test_loss: 0.9917\n",
      "round 134's user 0 is done\n",
      "round 135's user 1 is done\n",
      "Round135's train_acc: 90.95%, train_loss: 0.9915\n",
      "Round135's test_acc: 90.92%, test_loss: 0.9919\n",
      "round 135's user 0 is done\n",
      "round 136's user 0 is done\n",
      "Round136's train_acc: 90.97%, train_loss: 0.9917\n",
      "Round136's test_acc: 90.97%, test_loss: 0.9916\n",
      "round 136's user 1 is done\n",
      "round 137's user 1 is done\n",
      "Round137's train_acc: 90.68%, train_loss: 0.9943\n",
      "Round137's test_acc: 90.80%, test_loss: 0.9935\n",
      "round 137's user 0 is done\n",
      "round 138's user 1 is done\n",
      "Round138's train_acc: 90.90%, train_loss: 0.9921\n",
      "Round138's test_acc: 90.99%, test_loss: 0.9914\n",
      "round 138's user 0 is done\n",
      "round 139's user 1 is done\n",
      "Round139's train_acc: 90.94%, train_loss: 0.9917\n",
      "Round139's test_acc: 90.90%, test_loss: 0.9921\n",
      "round 139's user 0 is done\n",
      "round 140's user 1 is done\n",
      "Round140's train_acc: 90.70%, train_loss: 0.9942\n",
      "Round140's test_acc: 90.80%, test_loss: 0.9934\n",
      "round 140's user 0 is done\n",
      "round 141's user 0 is done\n",
      "Round141's train_acc: 91.02%, train_loss: 0.9912\n",
      "Round141's test_acc: 90.96%, test_loss: 0.9917\n",
      "round 141's user 1 is done\n",
      "round 142's user 1 is done\n",
      "Round142's train_acc: 90.96%, train_loss: 0.9915\n",
      "Round142's test_acc: 91.05%, test_loss: 0.9909\n",
      "round 142's user 0 is done\n",
      "round 143's user 1 is done\n",
      "Round143's train_acc: 90.87%, train_loss: 0.9923\n",
      "Round143's test_acc: 90.89%, test_loss: 0.9921\n",
      "round 143's user 0 is done\n",
      "round 144's user 1 is done\n",
      "Round144's train_acc: 91.00%, train_loss: 0.9911\n",
      "Round144's test_acc: 91.02%, test_loss: 0.9912\n",
      "round 144's user 0 is done\n",
      "round 145's user 0 is done\n",
      "Round145's train_acc: 90.89%, train_loss: 0.9922\n",
      "Round145's test_acc: 90.87%, test_loss: 0.9924\n",
      "round 145's user 1 is done\n",
      "round 146's user 1 is done\n",
      "Round146's train_acc: 90.96%, train_loss: 0.9914\n",
      "Round146's test_acc: 90.95%, test_loss: 0.9916\n",
      "round 146's user 0 is done\n",
      "round 147's user 1 is done\n",
      "Round147's train_acc: 91.17%, train_loss: 0.9894\n",
      "Round147's test_acc: 91.18%, test_loss: 0.9893\n",
      "round 147's user 0 is done\n",
      "round 148's user 0 is done\n",
      "Round148's train_acc: 91.19%, train_loss: 0.9892\n",
      "Round148's test_acc: 91.15%, test_loss: 0.9897\n",
      "round 148's user 1 is done\n",
      "round 149's user 1 is done\n",
      "Round149's train_acc: 90.77%, train_loss: 0.9935\n",
      "Round149's test_acc: 90.76%, test_loss: 0.9938\n",
      "round 149's user 0 is done\n",
      "round 150's user 0 is done\n",
      "Round150's train_acc: 91.02%, train_loss: 0.9906\n",
      "Round150's test_acc: 91.02%, test_loss: 0.9909\n",
      "round 150's user 1 is done\n",
      "round 151's user 1 is done\n",
      "Round151's train_acc: 90.83%, train_loss: 0.9925\n",
      "Round151's test_acc: 90.83%, test_loss: 0.9928\n",
      "round 151's user 0 is done\n",
      "round 152's user 1 is done\n",
      "Round152's train_acc: 91.13%, train_loss: 0.9897\n",
      "Round152's test_acc: 91.08%, test_loss: 0.9905\n",
      "round 152's user 0 is done\n",
      "round 153's user 1 is done\n",
      "Round153's train_acc: 91.22%, train_loss: 0.9888\n",
      "Round153's test_acc: 91.21%, test_loss: 0.9889\n",
      "round 153's user 0 is done\n",
      "round 154's user 1 is done\n",
      "Round154's train_acc: 91.12%, train_loss: 0.9898\n",
      "Round154's test_acc: 91.10%, test_loss: 0.9902\n",
      "round 154's user 0 is done\n",
      "round 155's user 1 is done\n",
      "Round155's train_acc: 90.81%, train_loss: 0.9934\n",
      "Round155's test_acc: 90.50%, test_loss: 0.9963\n",
      "round 155's user 0 is done\n",
      "round 156's user 0 is done\n",
      "Round156's train_acc: 91.18%, train_loss: 0.9892\n",
      "Round156's test_acc: 91.11%, test_loss: 0.9897\n",
      "round 156's user 1 is done\n",
      "round 157's user 1 is done\n",
      "Round157's train_acc: 91.03%, train_loss: 0.9905\n",
      "Round157's test_acc: 91.03%, test_loss: 0.9908\n",
      "round 157's user 0 is done\n",
      "round 158's user 1 is done\n",
      "Round158's train_acc: 91.20%, train_loss: 0.9890\n",
      "Round158's test_acc: 91.12%, test_loss: 0.9899\n",
      "round 158's user 0 is done\n",
      "round 159's user 0 is done\n",
      "Round159's train_acc: 90.99%, train_loss: 0.9913\n",
      "Round159's test_acc: 90.97%, test_loss: 0.9914\n",
      "round 159's user 1 is done\n",
      "round 160's user 0 is done\n",
      "Round160's train_acc: 91.23%, train_loss: 0.9889\n",
      "Round160's test_acc: 91.15%, test_loss: 0.9895\n",
      "round 160's user 1 is done\n",
      "round 161's user 1 is done\n",
      "Round161's train_acc: 91.32%, train_loss: 0.9878\n",
      "Round161's test_acc: 91.16%, test_loss: 0.9890\n",
      "round 161's user 0 is done\n",
      "round 162's user 0 is done\n",
      "Round162's train_acc: 91.32%, train_loss: 0.9877\n",
      "Round162's test_acc: 91.29%, test_loss: 0.9881\n",
      "round 162's user 1 is done\n",
      "round 163's user 0 is done\n",
      "Round163's train_acc: 91.26%, train_loss: 0.9888\n",
      "Round163's test_acc: 91.24%, test_loss: 0.9888\n",
      "round 163's user 1 is done\n",
      "round 164's user 1 is done\n",
      "Round164's train_acc: 91.44%, train_loss: 0.9868\n",
      "Round164's test_acc: 91.42%, test_loss: 0.9871\n",
      "round 164's user 0 is done\n",
      "round 165's user 1 is done\n",
      "Round165's train_acc: 91.59%, train_loss: 0.9850\n",
      "Round165's test_acc: 91.48%, test_loss: 0.9861\n",
      "round 165's user 0 is done\n",
      "round 166's user 0 is done\n",
      "Round166's train_acc: 91.59%, train_loss: 0.9851\n",
      "Round166's test_acc: 91.43%, test_loss: 0.9866\n",
      "round 166's user 1 is done\n",
      "round 167's user 1 is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round167's train_acc: 91.67%, train_loss: 0.9843\n",
      "Round167's test_acc: 91.62%, test_loss: 0.9848\n",
      "round 167's user 0 is done\n",
      "round 168's user 1 is done\n",
      "Round168's train_acc: 91.70%, train_loss: 0.9839\n",
      "Round168's test_acc: 91.56%, test_loss: 0.9855\n",
      "round 168's user 0 is done\n",
      "round 169's user 1 is done\n",
      "Round169's train_acc: 91.74%, train_loss: 0.9833\n",
      "Round169's test_acc: 91.63%, test_loss: 0.9845\n",
      "round 169's user 0 is done\n",
      "round 170's user 0 is done\n",
      "Round170's train_acc: 91.66%, train_loss: 0.9845\n",
      "Round170's test_acc: 91.53%, test_loss: 0.9857\n",
      "round 170's user 1 is done\n",
      "round 171's user 1 is done\n",
      "Round171's train_acc: 91.57%, train_loss: 0.9853\n",
      "Round171's test_acc: 91.60%, test_loss: 0.9852\n",
      "round 171's user 0 is done\n",
      "round 172's user 1 is done\n",
      "Round172's train_acc: 92.00%, train_loss: 0.9811\n",
      "Round172's test_acc: 91.82%, test_loss: 0.9828\n",
      "round 172's user 0 is done\n",
      "round 173's user 1 is done\n",
      "Round173's train_acc: 91.85%, train_loss: 0.9824\n",
      "Round173's test_acc: 91.75%, test_loss: 0.9836\n",
      "round 173's user 0 is done\n",
      "round 174's user 1 is done\n",
      "Round174's train_acc: 92.02%, train_loss: 0.9808\n",
      "Round174's test_acc: 91.81%, test_loss: 0.9830\n",
      "round 174's user 0 is done\n",
      "round 175's user 1 is done\n",
      "Round175's train_acc: 92.07%, train_loss: 0.9803\n",
      "Round175's test_acc: 91.94%, test_loss: 0.9819\n",
      "round 175's user 0 is done\n",
      "round 176's user 1 is done\n",
      "Round176's train_acc: 91.96%, train_loss: 0.9814\n",
      "Round176's test_acc: 91.97%, test_loss: 0.9817\n",
      "round 176's user 0 is done\n",
      "round 177's user 1 is done\n",
      "Round177's train_acc: 91.81%, train_loss: 0.9827\n",
      "Round177's test_acc: 91.67%, test_loss: 0.9842\n",
      "round 177's user 0 is done\n",
      "round 178's user 1 is done\n",
      "Round178's train_acc: 91.60%, train_loss: 0.9851\n",
      "Round178's test_acc: 91.55%, test_loss: 0.9855\n",
      "round 178's user 0 is done\n",
      "round 179's user 1 is done\n",
      "Round179's train_acc: 92.25%, train_loss: 0.9783\n",
      "Round179's test_acc: 92.13%, test_loss: 0.9796\n",
      "round 179's user 0 is done\n",
      "round 180's user 0 is done\n",
      "Round180's train_acc: 92.22%, train_loss: 0.9783\n",
      "Round180's test_acc: 92.11%, test_loss: 0.9796\n",
      "round 180's user 1 is done\n",
      "round 181's user 1 is done\n",
      "Round181's train_acc: 92.28%, train_loss: 0.9784\n",
      "Round181's test_acc: 92.03%, test_loss: 0.9807\n",
      "round 181's user 0 is done\n",
      "round 182's user 1 is done\n",
      "Round182's train_acc: 92.22%, train_loss: 0.9787\n",
      "Round182's test_acc: 92.05%, test_loss: 0.9806\n",
      "round 182's user 0 is done\n",
      "round 183's user 1 is done\n",
      "Round183's train_acc: 92.34%, train_loss: 0.9776\n",
      "Round183's test_acc: 92.08%, test_loss: 0.9801\n",
      "round 183's user 0 is done\n",
      "round 184's user 1 is done\n",
      "Round184's train_acc: 92.25%, train_loss: 0.9783\n",
      "Round184's test_acc: 92.27%, test_loss: 0.9788\n",
      "round 184's user 0 is done\n",
      "round 185's user 1 is done\n",
      "Round185's train_acc: 92.26%, train_loss: 0.9782\n",
      "Round185's test_acc: 92.03%, test_loss: 0.9805\n",
      "round 185's user 0 is done\n",
      "round 186's user 0 is done\n",
      "Round186's train_acc: 92.47%, train_loss: 0.9762\n",
      "Round186's test_acc: 92.15%, test_loss: 0.9795\n",
      "round 186's user 1 is done\n",
      "round 187's user 1 is done\n",
      "Round187's train_acc: 92.69%, train_loss: 0.9739\n",
      "Round187's test_acc: 92.31%, test_loss: 0.9778\n",
      "round 187's user 0 is done\n",
      "round 188's user 0 is done\n",
      "Round188's train_acc: 92.81%, train_loss: 0.9727\n",
      "Round188's test_acc: 92.49%, test_loss: 0.9763\n",
      "round 188's user 1 is done\n",
      "round 189's user 0 is done\n",
      "Round189's train_acc: 92.74%, train_loss: 0.9736\n",
      "Round189's test_acc: 92.30%, test_loss: 0.9779\n",
      "round 189's user 1 is done\n",
      "round 190's user 1 is done\n",
      "Round190's train_acc: 92.71%, train_loss: 0.9737\n",
      "Round190's test_acc: 92.47%, test_loss: 0.9762\n",
      "round 190's user 0 is done\n",
      "round 191's user 1 is done\n",
      "Round191's train_acc: 92.80%, train_loss: 0.9731\n",
      "Round191's test_acc: 92.38%, test_loss: 0.9772\n",
      "round 191's user 0 is done\n",
      "round 192's user 0 is done\n",
      "Round192's train_acc: 92.80%, train_loss: 0.9728\n",
      "Round192's test_acc: 92.60%, test_loss: 0.9750\n",
      "round 192's user 1 is done\n",
      "round 193's user 1 is done\n",
      "Round193's train_acc: 92.87%, train_loss: 0.9723\n",
      "Round193's test_acc: 92.59%, test_loss: 0.9750\n",
      "round 193's user 0 is done\n",
      "round 194's user 1 is done\n",
      "Round194's train_acc: 92.93%, train_loss: 0.9716\n",
      "Round194's test_acc: 92.58%, test_loss: 0.9749\n",
      "round 194's user 0 is done\n",
      "round 195's user 1 is done\n",
      "Round195's train_acc: 92.75%, train_loss: 0.9729\n",
      "Round195's test_acc: 92.42%, test_loss: 0.9766\n",
      "round 195's user 0 is done\n",
      "round 196's user 1 is done\n",
      "Round196's train_acc: 92.84%, train_loss: 0.9729\n",
      "Round196's test_acc: 92.44%, test_loss: 0.9766\n",
      "round 196's user 0 is done\n",
      "round 197's user 1 is done\n",
      "Round197's train_acc: 92.75%, train_loss: 0.9733\n",
      "Round197's test_acc: 92.38%, test_loss: 0.9773\n",
      "round 197's user 0 is done\n",
      "round 198's user 0 is done\n",
      "Round198's train_acc: 93.09%, train_loss: 0.9704\n",
      "Round198's test_acc: 92.68%, test_loss: 0.9744\n",
      "round 198's user 1 is done\n",
      "round 199's user 0 is done\n",
      "Round199's train_acc: 93.11%, train_loss: 0.9698\n",
      "Round199's test_acc: 92.66%, test_loss: 0.9739\n",
      "round 199's user 1 is done\n",
      "round 200's user 1 is done\n",
      "Round200's train_acc: 93.17%, train_loss: 0.9689\n",
      "Round200's test_acc: 92.84%, test_loss: 0.9727\n",
      "round 200's user 0 is done\n",
      "round 201's user 1 is done\n",
      "Round201's train_acc: 92.86%, train_loss: 0.9718\n",
      "Round201's test_acc: 92.48%, test_loss: 0.9758\n",
      "round 201's user 0 is done\n",
      "round 202's user 1 is done\n",
      "Round202's train_acc: 93.10%, train_loss: 0.9697\n",
      "Round202's test_acc: 92.74%, test_loss: 0.9733\n",
      "round 202's user 0 is done\n",
      "round 203's user 0 is done\n",
      "Round203's train_acc: 93.16%, train_loss: 0.9695\n",
      "Round203's test_acc: 92.74%, test_loss: 0.9735\n",
      "round 203's user 1 is done\n",
      "round 204's user 1 is done\n",
      "Round204's train_acc: 93.14%, train_loss: 0.9697\n",
      "Round204's test_acc: 92.80%, test_loss: 0.9730\n",
      "round 204's user 0 is done\n",
      "round 205's user 0 is done\n",
      "Round205's train_acc: 92.98%, train_loss: 0.9709\n",
      "Round205's test_acc: 92.71%, test_loss: 0.9736\n",
      "round 205's user 1 is done\n",
      "round 206's user 1 is done\n",
      "Round206's train_acc: 93.17%, train_loss: 0.9691\n",
      "Round206's test_acc: 92.71%, test_loss: 0.9739\n",
      "round 206's user 0 is done\n",
      "round 207's user 0 is done\n",
      "Round207's train_acc: 93.17%, train_loss: 0.9690\n",
      "Round207's test_acc: 92.85%, test_loss: 0.9725\n",
      "round 207's user 1 is done\n",
      "round 208's user 0 is done\n",
      "Round208's train_acc: 93.26%, train_loss: 0.9682\n",
      "Round208's test_acc: 92.92%, test_loss: 0.9719\n",
      "round 208's user 1 is done\n",
      "round 209's user 0 is done\n",
      "Round209's train_acc: 93.08%, train_loss: 0.9699\n",
      "Round209's test_acc: 92.74%, test_loss: 0.9735\n",
      "round 209's user 1 is done\n",
      "round 210's user 0 is done\n",
      "Round210's train_acc: 93.13%, train_loss: 0.9695\n",
      "Round210's test_acc: 92.60%, test_loss: 0.9746\n",
      "round 210's user 1 is done\n",
      "round 211's user 1 is done\n",
      "Round211's train_acc: 93.26%, train_loss: 0.9680\n",
      "Round211's test_acc: 92.81%, test_loss: 0.9727\n",
      "round 211's user 0 is done\n",
      "round 212's user 1 is done\n",
      "Round212's train_acc: 93.30%, train_loss: 0.9676\n",
      "Round212's test_acc: 92.91%, test_loss: 0.9717\n",
      "round 212's user 0 is done\n",
      "round 213's user 0 is done\n",
      "Round213's train_acc: 92.74%, train_loss: 0.9732\n",
      "Round213's test_acc: 92.41%, test_loss: 0.9767\n",
      "round 213's user 1 is done\n",
      "round 214's user 1 is done\n",
      "Round214's train_acc: 93.32%, train_loss: 0.9676\n",
      "Round214's test_acc: 92.94%, test_loss: 0.9716\n",
      "round 214's user 0 is done\n",
      "round 215's user 0 is done\n",
      "Round215's train_acc: 93.29%, train_loss: 0.9678\n",
      "Round215's test_acc: 92.88%, test_loss: 0.9721\n",
      "round 215's user 1 is done\n",
      "round 216's user 1 is done\n",
      "Round216's train_acc: 93.36%, train_loss: 0.9671\n",
      "Round216's test_acc: 93.01%, test_loss: 0.9707\n",
      "round 216's user 0 is done\n",
      "round 217's user 1 is done\n",
      "Round217's train_acc: 93.41%, train_loss: 0.9667\n",
      "Round217's test_acc: 93.02%, test_loss: 0.9708\n",
      "round 217's user 0 is done\n",
      "round 218's user 1 is done\n",
      "Round218's train_acc: 93.41%, train_loss: 0.9668\n",
      "Round218's test_acc: 93.12%, test_loss: 0.9700\n",
      "round 218's user 0 is done\n",
      "round 219's user 0 is done\n",
      "Round219's train_acc: 93.36%, train_loss: 0.9668\n",
      "Round219's test_acc: 92.93%, test_loss: 0.9713\n",
      "round 219's user 1 is done\n",
      "round 220's user 1 is done\n",
      "Round220's train_acc: 93.36%, train_loss: 0.9670\n",
      "Round220's test_acc: 92.80%, test_loss: 0.9727\n",
      "round 220's user 0 is done\n",
      "round 221's user 1 is done\n",
      "Round221's train_acc: 93.36%, train_loss: 0.9676\n",
      "Round221's test_acc: 92.91%, test_loss: 0.9721\n",
      "round 221's user 0 is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 222's user 1 is done\n",
      "Round222's train_acc: 93.18%, train_loss: 0.9689\n",
      "Round222's test_acc: 92.73%, test_loss: 0.9736\n",
      "round 222's user 0 is done\n",
      "round 223's user 1 is done\n",
      "Round223's train_acc: 93.33%, train_loss: 0.9675\n",
      "Round223's test_acc: 92.87%, test_loss: 0.9718\n",
      "round 223's user 0 is done\n",
      "round 224's user 0 is done\n",
      "Round224's train_acc: 93.39%, train_loss: 0.9670\n",
      "Round224's test_acc: 92.78%, test_loss: 0.9729\n",
      "round 224's user 1 is done\n",
      "round 225's user 1 is done\n",
      "Round225's train_acc: 93.22%, train_loss: 0.9686\n",
      "Round225's test_acc: 93.01%, test_loss: 0.9710\n",
      "round 225's user 0 is done\n",
      "round 226's user 1 is done\n",
      "Round226's train_acc: 93.34%, train_loss: 0.9672\n",
      "Round226's test_acc: 93.03%, test_loss: 0.9706\n",
      "round 226's user 0 is done\n",
      "round 227's user 1 is done\n",
      "Round227's train_acc: 93.40%, train_loss: 0.9667\n",
      "Round227's test_acc: 93.04%, test_loss: 0.9709\n",
      "round 227's user 0 is done\n",
      "round 228's user 1 is done\n",
      "Round228's train_acc: 93.42%, train_loss: 0.9667\n",
      "Round228's test_acc: 93.12%, test_loss: 0.9698\n",
      "round 228's user 0 is done\n",
      "round 229's user 1 is done\n",
      "Round229's train_acc: 93.50%, train_loss: 0.9657\n",
      "Round229's test_acc: 93.14%, test_loss: 0.9695\n",
      "round 229's user 0 is done\n",
      "round 230's user 1 is done\n",
      "Round230's train_acc: 93.43%, train_loss: 0.9667\n",
      "Round230's test_acc: 92.89%, test_loss: 0.9719\n",
      "round 230's user 0 is done\n",
      "round 231's user 1 is done\n",
      "Round231's train_acc: 93.39%, train_loss: 0.9669\n",
      "Round231's test_acc: 93.03%, test_loss: 0.9704\n",
      "round 231's user 0 is done\n",
      "round 232's user 1 is done\n",
      "Round232's train_acc: 93.57%, train_loss: 0.9649\n",
      "Round232's test_acc: 93.21%, test_loss: 0.9688\n",
      "round 232's user 0 is done\n",
      "round 233's user 1 is done\n",
      "Round233's train_acc: 93.44%, train_loss: 0.9664\n",
      "Round233's test_acc: 93.03%, test_loss: 0.9707\n",
      "round 233's user 0 is done\n",
      "round 234's user 1 is done\n",
      "Round234's train_acc: 93.37%, train_loss: 0.9673\n",
      "Round234's test_acc: 93.09%, test_loss: 0.9704\n",
      "round 234's user 0 is done\n",
      "round 235's user 1 is done\n",
      "Round235's train_acc: 93.20%, train_loss: 0.9691\n",
      "Round235's test_acc: 92.86%, test_loss: 0.9729\n",
      "round 235's user 0 is done\n",
      "round 236's user 1 is done\n",
      "Round236's train_acc: 93.56%, train_loss: 0.9651\n",
      "Round236's test_acc: 93.09%, test_loss: 0.9699\n",
      "round 236's user 0 is done\n",
      "round 237's user 1 is done\n",
      "Round237's train_acc: 93.40%, train_loss: 0.9672\n",
      "Round237's test_acc: 93.08%, test_loss: 0.9705\n",
      "round 237's user 0 is done\n",
      "round 238's user 1 is done\n",
      "Round238's train_acc: 93.53%, train_loss: 0.9657\n",
      "Round238's test_acc: 92.99%, test_loss: 0.9710\n",
      "round 238's user 0 is done\n",
      "round 239's user 1 is done\n",
      "Round239's train_acc: 93.34%, train_loss: 0.9672\n",
      "Round239's test_acc: 92.95%, test_loss: 0.9718\n",
      "round 239's user 0 is done\n",
      "round 240's user 1 is done\n",
      "Round240's train_acc: 93.54%, train_loss: 0.9651\n",
      "Round240's test_acc: 93.11%, test_loss: 0.9696\n",
      "round 240's user 0 is done\n",
      "round 241's user 1 is done\n",
      "Round241's train_acc: 93.67%, train_loss: 0.9638\n",
      "Round241's test_acc: 93.15%, test_loss: 0.9691\n",
      "round 241's user 0 is done\n",
      "round 242's user 1 is done\n",
      "Round242's train_acc: 93.90%, train_loss: 0.9622\n",
      "Round242's test_acc: 93.30%, test_loss: 0.9680\n",
      "round 242's user 0 is done\n",
      "round 243's user 1 is done\n",
      "Round243's train_acc: 93.83%, train_loss: 0.9633\n",
      "Round243's test_acc: 93.36%, test_loss: 0.9680\n",
      "round 243's user 0 is done\n",
      "round 244's user 1 is done\n",
      "Round244's train_acc: 95.91%, train_loss: 0.9484\n",
      "Round244's test_acc: 95.23%, test_loss: 0.9548\n",
      "round 244's user 0 is done\n",
      "round 245's user 1 is done\n",
      "Round245's train_acc: 98.26%, train_loss: 0.9223\n",
      "Round245's test_acc: 97.55%, test_loss: 0.9291\n",
      "round 245's user 0 is done\n",
      "round 246's user 1 is done\n",
      "Round246's train_acc: 98.66%, train_loss: 0.9184\n",
      "Round246's test_acc: 97.89%, test_loss: 0.9258\n",
      "round 246's user 0 is done\n",
      "round 247's user 1 is done\n",
      "Round247's train_acc: 98.72%, train_loss: 0.9175\n",
      "Round247's test_acc: 97.95%, test_loss: 0.9255\n",
      "round 247's user 0 is done\n",
      "round 248's user 1 is done\n",
      "Round248's train_acc: 98.78%, train_loss: 0.9173\n",
      "Round248's test_acc: 97.98%, test_loss: 0.9253\n",
      "round 248's user 0 is done\n",
      "round 249's user 1 is done\n",
      "Round249's train_acc: 98.60%, train_loss: 0.9188\n",
      "Round249's test_acc: 97.87%, test_loss: 0.9260\n",
      "round 249's user 0 is done\n",
      "round 250's user 0 is done\n",
      "Round250's train_acc: 98.63%, train_loss: 0.9188\n",
      "Round250's test_acc: 97.88%, test_loss: 0.9261\n",
      "round 250's user 1 is done\n",
      "round 251's user 1 is done\n",
      "Round251's train_acc: 98.89%, train_loss: 0.9161\n",
      "Round251's test_acc: 98.23%, test_loss: 0.9225\n",
      "round 251's user 0 is done\n",
      "round 252's user 1 is done\n",
      "Round252's train_acc: 98.84%, train_loss: 0.9166\n",
      "Round252's test_acc: 98.20%, test_loss: 0.9232\n",
      "round 252's user 0 is done\n",
      "round 253's user 1 is done\n",
      "Round253's train_acc: 98.82%, train_loss: 0.9165\n",
      "Round253's test_acc: 98.08%, test_loss: 0.9237\n",
      "round 253's user 0 is done\n",
      "round 254's user 1 is done\n",
      "Round254's train_acc: 98.72%, train_loss: 0.9178\n",
      "Round254's test_acc: 97.98%, test_loss: 0.9252\n",
      "round 254's user 0 is done\n",
      "round 255's user 1 is done\n",
      "Round255's train_acc: 98.85%, train_loss: 0.9165\n",
      "Round255's test_acc: 98.13%, test_loss: 0.9235\n",
      "round 255's user 0 is done\n",
      "round 256's user 1 is done\n",
      "Round256's train_acc: 98.82%, train_loss: 0.9166\n",
      "Round256's test_acc: 98.10%, test_loss: 0.9238\n",
      "round 256's user 0 is done\n",
      "round 257's user 0 is done\n",
      "Round257's train_acc: 98.83%, train_loss: 0.9169\n",
      "Round257's test_acc: 98.08%, test_loss: 0.9237\n",
      "round 257's user 1 is done\n",
      "round 258's user 1 is done\n",
      "Round258's train_acc: 98.78%, train_loss: 0.9173\n",
      "Round258's test_acc: 98.17%, test_loss: 0.9235\n",
      "round 258's user 0 is done\n",
      "round 259's user 1 is done\n",
      "Round259's train_acc: 98.87%, train_loss: 0.9162\n",
      "Round259's test_acc: 98.19%, test_loss: 0.9229\n",
      "round 259's user 0 is done\n",
      "round 260's user 0 is done\n",
      "Round260's train_acc: 98.54%, train_loss: 0.9197\n",
      "Round260's test_acc: 97.86%, test_loss: 0.9264\n",
      "round 260's user 1 is done\n",
      "round 261's user 0 is done\n",
      "Round261's train_acc: 98.68%, train_loss: 0.9179\n",
      "Round261's test_acc: 97.98%, test_loss: 0.9249\n",
      "round 261's user 1 is done\n",
      "round 262's user 0 is done\n",
      "Round262's train_acc: 98.44%, train_loss: 0.9203\n",
      "Round262's test_acc: 97.80%, test_loss: 0.9270\n",
      "round 262's user 1 is done\n",
      "round 263's user 1 is done\n",
      "Round263's train_acc: 98.58%, train_loss: 0.9190\n",
      "Round263's test_acc: 97.82%, test_loss: 0.9265\n",
      "round 263's user 0 is done\n",
      "round 264's user 1 is done\n",
      "Round264's train_acc: 98.78%, train_loss: 0.9170\n",
      "Round264's test_acc: 97.98%, test_loss: 0.9251\n",
      "round 264's user 0 is done\n",
      "round 265's user 0 is done\n",
      "Round265's train_acc: 98.70%, train_loss: 0.9181\n",
      "Round265's test_acc: 97.80%, test_loss: 0.9267\n",
      "round 265's user 1 is done\n",
      "round 266's user 0 is done\n",
      "Round266's train_acc: 98.84%, train_loss: 0.9164\n",
      "Round266's test_acc: 98.18%, test_loss: 0.9232\n",
      "round 266's user 1 is done\n",
      "round 267's user 1 is done\n",
      "Round267's train_acc: 98.72%, train_loss: 0.9179\n",
      "Round267's test_acc: 98.02%, test_loss: 0.9243\n",
      "round 267's user 0 is done\n",
      "round 268's user 0 is done\n",
      "Round268's train_acc: 98.89%, train_loss: 0.9159\n",
      "Round268's test_acc: 98.21%, test_loss: 0.9229\n",
      "round 268's user 1 is done\n",
      "round 269's user 0 is done\n",
      "Round269's train_acc: 98.81%, train_loss: 0.9166\n",
      "Round269's test_acc: 98.01%, test_loss: 0.9245\n",
      "round 269's user 1 is done\n",
      "round 270's user 0 is done\n",
      "Round270's train_acc: 98.88%, train_loss: 0.9161\n",
      "Round270's test_acc: 98.17%, test_loss: 0.9231\n",
      "round 270's user 1 is done\n",
      "round 271's user 1 is done\n",
      "Round271's train_acc: 98.87%, train_loss: 0.9162\n",
      "Round271's test_acc: 98.09%, test_loss: 0.9239\n",
      "round 271's user 0 is done\n",
      "round 272's user 1 is done\n",
      "Round272's train_acc: 98.52%, train_loss: 0.9197\n",
      "Round272's test_acc: 97.88%, test_loss: 0.9259\n",
      "round 272's user 0 is done\n",
      "round 273's user 0 is done\n",
      "Round273's train_acc: 98.91%, train_loss: 0.9160\n",
      "Round273's test_acc: 98.29%, test_loss: 0.9220\n",
      "round 273's user 1 is done\n",
      "round 274's user 0 is done\n",
      "Round274's train_acc: 98.91%, train_loss: 0.9156\n",
      "Round274's test_acc: 98.15%, test_loss: 0.9231\n",
      "round 274's user 1 is done\n",
      "round 275's user 0 is done\n",
      "Round275's train_acc: 98.90%, train_loss: 0.9161\n",
      "Round275's test_acc: 98.20%, test_loss: 0.9229\n",
      "round 275's user 1 is done\n",
      "round 276's user 0 is done\n",
      "Round276's train_acc: 98.97%, train_loss: 0.9151\n",
      "Round276's test_acc: 98.26%, test_loss: 0.9221\n",
      "round 276's user 1 is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 277's user 0 is done\n",
      "Round277's train_acc: 98.84%, train_loss: 0.9165\n",
      "Round277's test_acc: 98.17%, test_loss: 0.9232\n",
      "round 277's user 1 is done\n",
      "round 278's user 0 is done\n",
      "Round278's train_acc: 98.81%, train_loss: 0.9166\n",
      "Round278's test_acc: 98.19%, test_loss: 0.9229\n",
      "round 278's user 1 is done\n",
      "round 279's user 1 is done\n",
      "Round279's train_acc: 98.52%, train_loss: 0.9193\n",
      "Round279's test_acc: 97.92%, test_loss: 0.9255\n",
      "round 279's user 0 is done\n",
      "round 280's user 0 is done\n",
      "Round280's train_acc: 98.87%, train_loss: 0.9162\n",
      "Round280's test_acc: 98.27%, test_loss: 0.9224\n",
      "round 280's user 1 is done\n",
      "round 281's user 1 is done\n",
      "Round281's train_acc: 98.81%, train_loss: 0.9168\n",
      "Round281's test_acc: 97.96%, test_loss: 0.9250\n",
      "round 281's user 0 is done\n",
      "round 282's user 0 is done\n",
      "Round282's train_acc: 98.84%, train_loss: 0.9161\n",
      "Round282's test_acc: 98.13%, test_loss: 0.9236\n",
      "round 282's user 1 is done\n",
      "round 283's user 0 is done\n",
      "Round283's train_acc: 98.84%, train_loss: 0.9166\n",
      "Round283's test_acc: 98.08%, test_loss: 0.9238\n",
      "round 283's user 1 is done\n",
      "round 284's user 0 is done\n",
      "Round284's train_acc: 98.96%, train_loss: 0.9154\n",
      "Round284's test_acc: 98.27%, test_loss: 0.9221\n",
      "round 284's user 1 is done\n",
      "round 285's user 1 is done\n",
      "Round285's train_acc: 98.94%, train_loss: 0.9156\n",
      "Round285's test_acc: 98.28%, test_loss: 0.9221\n",
      "round 285's user 0 is done\n",
      "round 286's user 1 is done\n",
      "Round286's train_acc: 99.00%, train_loss: 0.9149\n",
      "Round286's test_acc: 98.32%, test_loss: 0.9216\n",
      "round 286's user 0 is done\n",
      "round 287's user 0 is done\n",
      "Round287's train_acc: 98.85%, train_loss: 0.9163\n",
      "Round287's test_acc: 98.16%, test_loss: 0.9232\n",
      "round 287's user 1 is done\n",
      "round 288's user 0 is done\n",
      "Round288's train_acc: 98.96%, train_loss: 0.9154\n",
      "Round288's test_acc: 98.23%, test_loss: 0.9224\n",
      "round 288's user 1 is done\n",
      "round 289's user 1 is done\n",
      "Round289's train_acc: 98.92%, train_loss: 0.9155\n",
      "Round289's test_acc: 98.22%, test_loss: 0.9224\n",
      "round 289's user 0 is done\n",
      "round 290's user 0 is done\n",
      "Round290's train_acc: 98.99%, train_loss: 0.9151\n",
      "Round290's test_acc: 98.25%, test_loss: 0.9223\n",
      "round 290's user 1 is done\n",
      "round 291's user 1 is done\n",
      "Round291's train_acc: 98.89%, train_loss: 0.9160\n",
      "Round291's test_acc: 98.14%, test_loss: 0.9231\n",
      "round 291's user 0 is done\n",
      "round 292's user 1 is done\n",
      "Round292's train_acc: 98.69%, train_loss: 0.9179\n",
      "Round292's test_acc: 98.12%, test_loss: 0.9235\n",
      "round 292's user 0 is done\n",
      "round 293's user 1 is done\n",
      "Round293's train_acc: 98.95%, train_loss: 0.9154\n",
      "Round293's test_acc: 98.26%, test_loss: 0.9223\n",
      "round 293's user 0 is done\n",
      "round 294's user 1 is done\n",
      "Round294's train_acc: 99.00%, train_loss: 0.9150\n",
      "Round294's test_acc: 98.30%, test_loss: 0.9219\n",
      "round 294's user 0 is done\n",
      "round 295's user 1 is done\n",
      "Round295's train_acc: 98.98%, train_loss: 0.9150\n",
      "Round295's test_acc: 98.23%, test_loss: 0.9224\n",
      "round 295's user 0 is done\n",
      "round 296's user 1 is done\n",
      "Round296's train_acc: 98.90%, train_loss: 0.9159\n",
      "Round296's test_acc: 98.23%, test_loss: 0.9222\n",
      "round 296's user 0 is done\n",
      "round 297's user 1 is done\n",
      "Round297's train_acc: 98.78%, train_loss: 0.9169\n",
      "Round297's test_acc: 97.99%, test_loss: 0.9249\n",
      "round 297's user 0 is done\n",
      "round 298's user 1 is done\n",
      "Round298's train_acc: 99.00%, train_loss: 0.9148\n",
      "Round298's test_acc: 98.23%, test_loss: 0.9226\n",
      "round 298's user 0 is done\n",
      "round 299's user 1 is done\n",
      "Round299's train_acc: 98.90%, train_loss: 0.9161\n",
      "Round299's test_acc: 98.08%, test_loss: 0.9238\n",
      "round 299's user 0 is done\n",
      "round 300's user 1 is done\n",
      "Round300's train_acc: 98.76%, train_loss: 0.9171\n",
      "Round300's test_acc: 98.07%, test_loss: 0.9240\n",
      "round 300's user 0 is done\n",
      "round 301's user 1 is done\n",
      "Round301's train_acc: 98.96%, train_loss: 0.9152\n",
      "Round301's test_acc: 98.27%, test_loss: 0.9221\n",
      "round 301's user 0 is done\n",
      "round 302's user 0 is done\n",
      "Round302's train_acc: 98.92%, train_loss: 0.9156\n",
      "Round302's test_acc: 98.21%, test_loss: 0.9225\n",
      "round 302's user 1 is done\n",
      "round 303's user 1 is done\n",
      "Round303's train_acc: 98.77%, train_loss: 0.9172\n",
      "Round303's test_acc: 98.17%, test_loss: 0.9229\n",
      "round 303's user 0 is done\n",
      "round 304's user 0 is done\n",
      "Round304's train_acc: 98.91%, train_loss: 0.9158\n",
      "Round304's test_acc: 98.22%, test_loss: 0.9225\n",
      "round 304's user 1 is done\n",
      "round 305's user 1 is done\n",
      "Round305's train_acc: 98.95%, train_loss: 0.9153\n",
      "Round305's test_acc: 98.31%, test_loss: 0.9217\n",
      "round 305's user 0 is done\n",
      "round 306's user 1 is done\n",
      "Round306's train_acc: 98.94%, train_loss: 0.9154\n",
      "Round306's test_acc: 98.29%, test_loss: 0.9218\n",
      "round 306's user 0 is done\n",
      "round 307's user 1 is done\n",
      "Round307's train_acc: 98.92%, train_loss: 0.9156\n",
      "Round307's test_acc: 98.40%, test_loss: 0.9209\n",
      "round 307's user 0 is done\n",
      "round 308's user 1 is done\n",
      "Round308's train_acc: 98.99%, train_loss: 0.9150\n",
      "Round308's test_acc: 98.39%, test_loss: 0.9210\n",
      "round 308's user 0 is done\n",
      "round 309's user 1 is done\n",
      "Round309's train_acc: 98.91%, train_loss: 0.9158\n",
      "Round309's test_acc: 98.19%, test_loss: 0.9228\n",
      "round 309's user 0 is done\n",
      "round 310's user 1 is done\n",
      "Round310's train_acc: 99.00%, train_loss: 0.9148\n",
      "Round310's test_acc: 98.44%, test_loss: 0.9205\n",
      "round 310's user 0 is done\n",
      "round 311's user 1 is done\n",
      "Round311's train_acc: 98.88%, train_loss: 0.9159\n",
      "Round311's test_acc: 98.23%, test_loss: 0.9227\n",
      "round 311's user 0 is done\n",
      "round 312's user 0 is done\n",
      "Round312's train_acc: 98.92%, train_loss: 0.9155\n",
      "Round312's test_acc: 98.29%, test_loss: 0.9219\n",
      "round 312's user 1 is done\n",
      "round 313's user 1 is done\n",
      "Round313's train_acc: 99.06%, train_loss: 0.9144\n",
      "Round313's test_acc: 98.30%, test_loss: 0.9217\n",
      "round 313's user 0 is done\n",
      "round 314's user 1 is done\n",
      "Round314's train_acc: 98.93%, train_loss: 0.9155\n",
      "Round314's test_acc: 98.24%, test_loss: 0.9223\n",
      "round 314's user 0 is done\n",
      "round 315's user 0 is done\n",
      "Round315's train_acc: 98.93%, train_loss: 0.9156\n",
      "Round315's test_acc: 98.23%, test_loss: 0.9224\n",
      "round 315's user 1 is done\n",
      "round 316's user 1 is done\n",
      "Round316's train_acc: 99.00%, train_loss: 0.9150\n",
      "Round316's test_acc: 98.30%, test_loss: 0.9220\n",
      "round 316's user 0 is done\n",
      "round 317's user 0 is done\n",
      "Round317's train_acc: 99.00%, train_loss: 0.9148\n",
      "Round317's test_acc: 98.23%, test_loss: 0.9224\n",
      "round 317's user 1 is done\n",
      "round 318's user 0 is done\n",
      "Round318's train_acc: 98.87%, train_loss: 0.9163\n",
      "Round318's test_acc: 98.14%, test_loss: 0.9232\n",
      "round 318's user 1 is done\n",
      "round 319's user 0 is done\n",
      "Round319's train_acc: 98.95%, train_loss: 0.9154\n",
      "Round319's test_acc: 98.17%, test_loss: 0.9231\n",
      "round 319's user 1 is done\n",
      "round 320's user 0 is done\n",
      "Round320's train_acc: 98.96%, train_loss: 0.9152\n",
      "Round320's test_acc: 98.33%, test_loss: 0.9216\n",
      "round 320's user 1 is done\n",
      "round 321's user 1 is done\n",
      "Round321's train_acc: 98.97%, train_loss: 0.9152\n",
      "Round321's test_acc: 98.15%, test_loss: 0.9233\n",
      "round 321's user 0 is done\n",
      "round 322's user 1 is done\n",
      "Round322's train_acc: 99.03%, train_loss: 0.9145\n",
      "Round322's test_acc: 98.33%, test_loss: 0.9215\n",
      "round 322's user 0 is done\n",
      "round 323's user 1 is done\n",
      "Round323's train_acc: 98.85%, train_loss: 0.9162\n",
      "Round323's test_acc: 98.16%, test_loss: 0.9232\n",
      "round 323's user 0 is done\n",
      "round 324's user 1 is done\n",
      "Round324's train_acc: 99.03%, train_loss: 0.9145\n",
      "Round324's test_acc: 98.34%, test_loss: 0.9215\n",
      "round 324's user 0 is done\n",
      "round 325's user 0 is done\n",
      "Round325's train_acc: 98.98%, train_loss: 0.9150\n",
      "Round325's test_acc: 98.26%, test_loss: 0.9221\n",
      "round 325's user 1 is done\n",
      "round 326's user 0 is done\n",
      "Round326's train_acc: 99.01%, train_loss: 0.9147\n",
      "Round326's test_acc: 98.25%, test_loss: 0.9223\n",
      "round 326's user 1 is done\n",
      "round 327's user 0 is done\n",
      "Round327's train_acc: 99.07%, train_loss: 0.9142\n",
      "Round327's test_acc: 98.35%, test_loss: 0.9214\n",
      "round 327's user 1 is done\n",
      "round 328's user 0 is done\n",
      "Round328's train_acc: 98.86%, train_loss: 0.9162\n",
      "Round328's test_acc: 98.10%, test_loss: 0.9235\n",
      "round 328's user 1 is done\n",
      "round 329's user 1 is done\n",
      "Round329's train_acc: 98.44%, train_loss: 0.9201\n",
      "Round329's test_acc: 97.76%, test_loss: 0.9272\n",
      "round 329's user 0 is done\n",
      "round 330's user 0 is done\n",
      "Round330's train_acc: 99.04%, train_loss: 0.9144\n",
      "Round330's test_acc: 98.34%, test_loss: 0.9214\n",
      "round 330's user 1 is done\n",
      "round 331's user 1 is done\n",
      "Round331's train_acc: 98.95%, train_loss: 0.9153\n",
      "Round331's test_acc: 98.17%, test_loss: 0.9232\n",
      "round 331's user 0 is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 332's user 1 is done\n",
      "Round332's train_acc: 99.01%, train_loss: 0.9146\n",
      "Round332's test_acc: 98.31%, test_loss: 0.9218\n",
      "round 332's user 0 is done\n",
      "round 333's user 1 is done\n",
      "Round333's train_acc: 98.83%, train_loss: 0.9166\n",
      "Round333's test_acc: 98.06%, test_loss: 0.9244\n",
      "round 333's user 0 is done\n",
      "round 334's user 1 is done\n",
      "Round334's train_acc: 99.06%, train_loss: 0.9142\n",
      "Round334's test_acc: 98.15%, test_loss: 0.9230\n",
      "round 334's user 0 is done\n",
      "round 335's user 0 is done\n",
      "Round335's train_acc: 99.10%, train_loss: 0.9139\n",
      "Round335's test_acc: 98.29%, test_loss: 0.9219\n",
      "round 335's user 1 is done\n",
      "round 336's user 0 is done\n",
      "Round336's train_acc: 98.89%, train_loss: 0.9160\n",
      "Round336's test_acc: 98.14%, test_loss: 0.9233\n",
      "round 336's user 1 is done\n",
      "round 337's user 1 is done\n",
      "Round337's train_acc: 99.03%, train_loss: 0.9145\n",
      "Round337's test_acc: 98.34%, test_loss: 0.9216\n",
      "round 337's user 0 is done\n",
      "round 338's user 1 is done\n",
      "Round338's train_acc: 99.09%, train_loss: 0.9141\n",
      "Round338's test_acc: 98.41%, test_loss: 0.9206\n",
      "round 338's user 0 is done\n",
      "round 339's user 1 is done\n",
      "Round339's train_acc: 98.74%, train_loss: 0.9173\n",
      "Round339's test_acc: 97.99%, test_loss: 0.9248\n",
      "round 339's user 0 is done\n",
      "round 340's user 1 is done\n",
      "Round340's train_acc: 98.93%, train_loss: 0.9154\n",
      "Round340's test_acc: 98.18%, test_loss: 0.9230\n",
      "round 340's user 0 is done\n",
      "round 341's user 1 is done\n",
      "Round341's train_acc: 98.98%, train_loss: 0.9151\n",
      "Round341's test_acc: 98.29%, test_loss: 0.9221\n",
      "round 341's user 0 is done\n",
      "round 342's user 1 is done\n",
      "Round342's train_acc: 98.97%, train_loss: 0.9151\n",
      "Round342's test_acc: 98.29%, test_loss: 0.9219\n",
      "round 342's user 0 is done\n",
      "round 343's user 1 is done\n",
      "Round343's train_acc: 99.09%, train_loss: 0.9139\n",
      "Round343's test_acc: 98.32%, test_loss: 0.9217\n",
      "round 343's user 0 is done\n",
      "round 344's user 0 is done\n",
      "Round344's train_acc: 98.98%, train_loss: 0.9150\n",
      "Round344's test_acc: 98.23%, test_loss: 0.9224\n",
      "round 344's user 1 is done\n",
      "round 345's user 1 is done\n",
      "Round345's train_acc: 99.05%, train_loss: 0.9143\n",
      "Round345's test_acc: 98.32%, test_loss: 0.9216\n",
      "round 345's user 0 is done\n",
      "round 346's user 1 is done\n",
      "Round346's train_acc: 99.00%, train_loss: 0.9148\n",
      "Round346's test_acc: 98.20%, test_loss: 0.9228\n",
      "round 346's user 0 is done\n",
      "round 347's user 1 is done\n",
      "Round347's train_acc: 99.13%, train_loss: 0.9136\n",
      "Round347's test_acc: 98.22%, test_loss: 0.9224\n",
      "round 347's user 0 is done\n",
      "round 348's user 0 is done\n",
      "Round348's train_acc: 99.00%, train_loss: 0.9147\n",
      "Round348's test_acc: 98.21%, test_loss: 0.9228\n",
      "round 348's user 1 is done\n",
      "round 349's user 0 is done\n",
      "Round349's train_acc: 99.09%, train_loss: 0.9137\n",
      "Round349's test_acc: 98.25%, test_loss: 0.9220\n",
      "round 349's user 1 is done\n",
      "round 350's user 0 is done\n",
      "Round350's train_acc: 99.09%, train_loss: 0.9140\n",
      "Round350's test_acc: 98.26%, test_loss: 0.9223\n",
      "round 350's user 1 is done\n",
      "round 351's user 0 is done\n",
      "Round351's train_acc: 99.12%, train_loss: 0.9137\n",
      "Round351's test_acc: 98.32%, test_loss: 0.9216\n",
      "round 351's user 1 is done\n",
      "round 352's user 1 is done\n",
      "Round352's train_acc: 99.10%, train_loss: 0.9138\n",
      "Round352's test_acc: 98.31%, test_loss: 0.9217\n",
      "round 352's user 0 is done\n",
      "round 353's user 0 is done\n",
      "Round353's train_acc: 99.05%, train_loss: 0.9144\n",
      "Round353's test_acc: 98.35%, test_loss: 0.9213\n",
      "round 353's user 1 is done\n",
      "round 354's user 0 is done\n",
      "Round354's train_acc: 99.06%, train_loss: 0.9142\n",
      "Round354's test_acc: 98.27%, test_loss: 0.9219\n",
      "round 354's user 1 is done\n",
      "round 355's user 0 is done\n",
      "Round355's train_acc: 98.98%, train_loss: 0.9151\n",
      "Round355's test_acc: 98.25%, test_loss: 0.9223\n",
      "round 355's user 1 is done\n",
      "round 356's user 1 is done\n",
      "Round356's train_acc: 98.95%, train_loss: 0.9150\n",
      "Round356's test_acc: 98.08%, test_loss: 0.9239\n",
      "round 356's user 0 is done\n",
      "round 357's user 1 is done\n",
      "Round357's train_acc: 98.83%, train_loss: 0.9163\n",
      "Round357's test_acc: 98.04%, test_loss: 0.9242\n",
      "round 357's user 0 is done\n",
      "round 358's user 1 is done\n",
      "Round358's train_acc: 99.16%, train_loss: 0.9133\n",
      "Round358's test_acc: 98.26%, test_loss: 0.9220\n",
      "round 358's user 0 is done\n",
      "round 359's user 0 is done\n",
      "Round359's train_acc: 99.05%, train_loss: 0.9144\n",
      "Round359's test_acc: 98.29%, test_loss: 0.9220\n",
      "round 359's user 1 is done\n",
      "round 360's user 1 is done\n",
      "Round360's train_acc: 98.95%, train_loss: 0.9153\n",
      "Round360's test_acc: 98.07%, test_loss: 0.9238\n",
      "round 360's user 0 is done\n",
      "round 361's user 0 is done\n",
      "Round361's train_acc: 99.09%, train_loss: 0.9142\n",
      "Round361's test_acc: 98.25%, test_loss: 0.9224\n",
      "round 361's user 1 is done\n",
      "round 362's user 0 is done\n",
      "Round362's train_acc: 99.06%, train_loss: 0.9141\n",
      "Round362's test_acc: 98.36%, test_loss: 0.9211\n",
      "round 362's user 1 is done\n",
      "round 363's user 1 is done\n",
      "Round363's train_acc: 99.01%, train_loss: 0.9148\n",
      "Round363's test_acc: 98.23%, test_loss: 0.9223\n",
      "round 363's user 0 is done\n",
      "round 364's user 1 is done\n",
      "Round364's train_acc: 99.07%, train_loss: 0.9142\n",
      "Round364's test_acc: 98.29%, test_loss: 0.9219\n",
      "round 364's user 0 is done\n",
      "round 365's user 1 is done\n",
      "Round365's train_acc: 98.99%, train_loss: 0.9149\n",
      "Round365's test_acc: 98.15%, test_loss: 0.9233\n",
      "round 365's user 0 is done\n",
      "round 366's user 0 is done\n",
      "Round366's train_acc: 99.10%, train_loss: 0.9138\n",
      "Round366's test_acc: 98.33%, test_loss: 0.9215\n",
      "round 366's user 1 is done\n",
      "round 367's user 0 is done\n",
      "Round367's train_acc: 99.09%, train_loss: 0.9139\n",
      "Round367's test_acc: 98.32%, test_loss: 0.9217\n",
      "round 367's user 1 is done\n",
      "round 368's user 1 is done\n",
      "Round368's train_acc: 99.06%, train_loss: 0.9143\n",
      "Round368's test_acc: 98.22%, test_loss: 0.9224\n",
      "round 368's user 0 is done\n",
      "round 369's user 1 is done\n",
      "Round369's train_acc: 99.08%, train_loss: 0.9141\n",
      "Round369's test_acc: 98.26%, test_loss: 0.9221\n",
      "round 369's user 0 is done\n",
      "round 370's user 1 is done\n",
      "Round370's train_acc: 98.83%, train_loss: 0.9166\n",
      "Round370's test_acc: 97.98%, test_loss: 0.9249\n",
      "round 370's user 0 is done\n",
      "round 371's user 1 is done\n",
      "Round371's train_acc: 98.94%, train_loss: 0.9153\n",
      "Round371's test_acc: 98.22%, test_loss: 0.9226\n",
      "round 371's user 0 is done\n",
      "round 372's user 1 is done\n",
      "Round372's train_acc: 98.94%, train_loss: 0.9155\n",
      "Round372's test_acc: 98.11%, test_loss: 0.9237\n",
      "round 372's user 0 is done\n",
      "round 373's user 1 is done\n",
      "Round373's train_acc: 99.12%, train_loss: 0.9138\n",
      "Round373's test_acc: 98.32%, test_loss: 0.9217\n",
      "round 373's user 0 is done\n",
      "round 374's user 1 is done\n",
      "Round374's train_acc: 98.99%, train_loss: 0.9150\n",
      "Round374's test_acc: 98.22%, test_loss: 0.9227\n",
      "round 374's user 0 is done\n",
      "round 375's user 1 is done\n",
      "Round375's train_acc: 99.15%, train_loss: 0.9134\n",
      "Round375's test_acc: 98.38%, test_loss: 0.9210\n",
      "round 375's user 0 is done\n",
      "round 376's user 0 is done\n",
      "Round376's train_acc: 99.11%, train_loss: 0.9137\n",
      "Round376's test_acc: 98.29%, test_loss: 0.9219\n",
      "round 376's user 1 is done\n",
      "round 377's user 0 is done\n",
      "Round377's train_acc: 99.00%, train_loss: 0.9149\n",
      "Round377's test_acc: 98.26%, test_loss: 0.9221\n",
      "round 377's user 1 is done\n",
      "round 378's user 1 is done\n",
      "Round378's train_acc: 99.09%, train_loss: 0.9140\n",
      "Round378's test_acc: 98.33%, test_loss: 0.9216\n",
      "round 378's user 0 is done\n",
      "round 379's user 0 is done\n",
      "Round379's train_acc: 99.13%, train_loss: 0.9135\n",
      "Round379's test_acc: 98.37%, test_loss: 0.9209\n",
      "round 379's user 1 is done\n",
      "round 380's user 0 is done\n",
      "Round380's train_acc: 99.02%, train_loss: 0.9145\n",
      "Round380's test_acc: 98.25%, test_loss: 0.9223\n",
      "round 380's user 1 is done\n",
      "round 381's user 0 is done\n",
      "Round381's train_acc: 98.98%, train_loss: 0.9151\n",
      "Round381's test_acc: 98.18%, test_loss: 0.9229\n",
      "round 381's user 1 is done\n",
      "round 382's user 0 is done\n",
      "Round382's train_acc: 98.81%, train_loss: 0.9165\n",
      "Round382's test_acc: 98.07%, test_loss: 0.9241\n",
      "round 382's user 1 is done\n",
      "round 383's user 1 is done\n",
      "Round383's train_acc: 98.74%, train_loss: 0.9175\n",
      "Round383's test_acc: 98.04%, test_loss: 0.9243\n",
      "round 383's user 0 is done\n",
      "round 384's user 0 is done\n",
      "Round384's train_acc: 98.79%, train_loss: 0.9170\n",
      "Round384's test_acc: 98.17%, test_loss: 0.9231\n",
      "round 384's user 1 is done\n",
      "round 385's user 0 is done\n",
      "Round385's train_acc: 99.11%, train_loss: 0.9138\n",
      "Round385's test_acc: 98.38%, test_loss: 0.9210\n",
      "round 385's user 1 is done\n",
      "round 386's user 1 is done\n",
      "Round386's train_acc: 99.01%, train_loss: 0.9146\n",
      "Round386's test_acc: 98.36%, test_loss: 0.9210\n",
      "round 386's user 0 is done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 387's user 1 is done\n",
      "Round387's train_acc: 99.06%, train_loss: 0.9142\n",
      "Round387's test_acc: 98.38%, test_loss: 0.9209\n",
      "round 387's user 0 is done\n",
      "round 388's user 0 is done\n",
      "Round388's train_acc: 99.03%, train_loss: 0.9145\n",
      "Round388's test_acc: 98.26%, test_loss: 0.9223\n",
      "round 388's user 1 is done\n",
      "round 389's user 0 is done\n",
      "Round389's train_acc: 99.09%, train_loss: 0.9139\n",
      "Round389's test_acc: 98.35%, test_loss: 0.9213\n",
      "round 389's user 1 is done\n",
      "round 390's user 1 is done\n",
      "Round390's train_acc: 99.04%, train_loss: 0.9143\n",
      "Round390's test_acc: 98.33%, test_loss: 0.9214\n",
      "round 390's user 0 is done\n",
      "round 391's user 0 is done\n",
      "Round391's train_acc: 98.90%, train_loss: 0.9156\n",
      "Round391's test_acc: 98.18%, test_loss: 0.9230\n",
      "round 391's user 1 is done\n",
      "round 392's user 1 is done\n",
      "Round392's train_acc: 99.03%, train_loss: 0.9145\n",
      "Round392's test_acc: 98.22%, test_loss: 0.9225\n",
      "round 392's user 0 is done\n",
      "round 393's user 1 is done\n",
      "Round393's train_acc: 99.05%, train_loss: 0.9144\n",
      "Round393's test_acc: 98.32%, test_loss: 0.9217\n",
      "round 393's user 0 is done\n",
      "round 394's user 1 is done\n",
      "Round394's train_acc: 99.04%, train_loss: 0.9144\n",
      "Round394's test_acc: 98.20%, test_loss: 0.9225\n",
      "round 394's user 0 is done\n",
      "round 395's user 0 is done\n",
      "Round395's train_acc: 99.11%, train_loss: 0.9138\n",
      "Round395's test_acc: 98.17%, test_loss: 0.9227\n",
      "round 395's user 1 is done\n",
      "round 396's user 0 is done\n",
      "Round396's train_acc: 98.92%, train_loss: 0.9156\n",
      "Round396's test_acc: 98.19%, test_loss: 0.9229\n",
      "round 396's user 1 is done\n",
      "round 397's user 0 is done\n",
      "Round397's train_acc: 99.07%, train_loss: 0.9140\n",
      "Round397's test_acc: 98.38%, test_loss: 0.9211\n",
      "round 397's user 1 is done\n",
      "round 398's user 1 is done\n",
      "Round398's train_acc: 99.11%, train_loss: 0.9138\n",
      "Round398's test_acc: 98.28%, test_loss: 0.9218\n",
      "round 398's user 0 is done\n",
      "round 399's user 0 is done\n",
      "0 is complite\n",
      "Round399's train_acc: 99.10%, train_loss: 0.9138\n",
      "Round399's test_acc: 98.26%, test_loss: 0.9222\n",
      "round 399's user 1 is done\n",
      "1 is complite\n",
      "TrainingTime: 3306.747008085251 sec\n"
     ]
    }
   ],
   "source": [
    "run_thread(receive, users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print commmunication overheads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---total_sendsize_list---\n",
      "total_sendsize size: 22109196148 bytes\n",
      "number of total_send:  166402\n",
      "\n",
      "\n",
      "---total_receivesize_list---\n",
      "total receive sizes: 22184537712 bytes\n",
      "number of total receive:  166402\n",
      "\n",
      "\n",
      "---client_sendsize_list(user0)---\n",
      "total client_sendsizes(user0): 11054598074 bytes\n",
      "number of client_send(user0):  83201\n",
      "\n",
      "\n",
      "---client_receivesize_list(user0)---\n",
      "total client_receive sizes(user0): 11092268856 bytes\n",
      "number of client_send(user0):  83201\n",
      "\n",
      "\n",
      "---client_sendsize_list(user1)---\n",
      "total client_sendsizes(user1): 11054598074 bytes\n",
      "number of client_send(user1):  83201\n",
      "\n",
      "\n",
      "---client_receivesize_list(user1)---\n",
      "total client_receive sizes(user1): 11092268856 bytes\n",
      "number of client_send(user1):  83201\n",
      "\n",
      "\n",
      "---train_sendsize_list---\n",
      "total train_sendsizes: 22109196024 bytes\n",
      "number of train_send:  166400\n",
      "\n",
      "\n",
      "---train_receivesize_list---\n",
      "total train_receivesizes: 22184537600 bytes\n",
      "number of train_receive:  166400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---total_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in total_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
    "print(\"number of total_send: \", len(total_sendsize_list))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in total_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
    "print(\"number of total receive: \", len(total_receivesize_list) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(users):\n",
    "    print('---client_sendsize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_sendsizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_sendsize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_receive sizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_receivesize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_send: \", len(train_sendsize_list) )\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation after trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc of each acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ecgnet(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu4): LeakyReLU(negative_slope=0.01)\n",
       "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear5): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (relu5): LeakyReLU(negative_slope=0.01)\n",
       "  (linear6): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (softmax6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_client.load_state_dict(global_c_weights)\n",
    "ecg_client.to(device)\n",
    "\n",
    "ecg_server.load_state_dict(global_s_weights)\n",
    "ecg_server.to(device)\n",
    "\n",
    "ecg_client_dict = ecg_client.state_dict()\n",
    "ecg_server_dict = ecg_server.state_dict()\n",
    "ecg_original_dict = ecg_net.state_dict()\n",
    "\n",
    "ecg_original_dict.update(ecg_client_dict)\n",
    "ecg_original_dict.update(ecg_server_dict)\n",
    "\n",
    "ecg_net.load_state_dict(ecg_original_dict)\n",
    "ecg_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 99.10%, train_loss: 0.9138\n",
      "test_acc: 98.26%, test_loss: 0.9222\n"
     ]
    }
   ],
   "source": [
    "# train acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    train_loss = 0.0\n",
    "    for j, trn in enumerate(train_loader):\n",
    "        trn_x, trn_label = trn\n",
    "        trn_x = trn_x.to(device)\n",
    "\n",
    "        trn_label = trn_label.clone().detach().long().to(device)\n",
    "\n",
    "\n",
    "        #trn_output = ecg_net(trn_x)\n",
    "        trn_output = ecg_client(trn_x)\n",
    "        trn_output = ecg_server(trn_output)\n",
    "        \n",
    "        loss = criterion(trn_output, trn_label)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        model_label = trn_output.argmax(dim=1)\n",
    "        corr = trn_label[trn_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += trn_label.size(0)\n",
    "    train_accuracy = corr_num / total_num * 100\n",
    "    r_train_loss = train_loss / len(train_loader)\n",
    "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(train_accuracy, r_train_loss))\n",
    "\n",
    "# test acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.to(device)\n",
    "\n",
    "        #val_output = ecg_net(val_x)\n",
    "        val_output = ecg_client(val_x)\n",
    "        val_output = ecg_server(val_output)\n",
    "        \n",
    "        val_label = val_label.long()\n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "    test_accuracy = corr_num / total_num * 100\n",
    "    test_loss = val_loss / len(test_loader)\n",
    "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format(test_accuracy, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     N : 97 %\n",
      "Accuracy of     L : 99 %\n",
      "Accuracy of     R : 99 %\n",
      "Accuracy of     A : 90 %\n",
      "Accuracy of     V : 99 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['N', 'L', 'R', 'A', 'V']\n",
    "\n",
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x, labels = data\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "#         outputs = ecg_net(x)\n",
    "        outputs = ecg_client(x)\n",
    "        outputs = ecg_server(outputs)\n",
    "\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Accuracy of %5s : %2d %%\" % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly save our trained model:\n",
    "PATH = './ecg_hy_model.pth'\n",
    "torch.save(ecg_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
